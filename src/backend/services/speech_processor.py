# ã“ã“ã« Google Cloud Speech-to-Text ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹æ„Ÿã˜ã§ï¼
from google.cloud import speech_v1p1beta1 as speech # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ã†ã‚ˆï¼
from google.api_core import exceptions
import asyncio
import pyaudio
import logging # logging ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os # ç’°å¢ƒå¤‰æ•°ã®ãŸã‚ã«è¿½åŠ 
import time
import threading

# --- Pythonã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œç´¢ãƒ‘ã‚¹ã«srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ  ---
import sys
# speech_processor.py ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (src/backend/services)
_CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ (src/backend/services -> src/backend -> src)
_SRC_DIR = os.path.abspath(os.path.join(_CURRENT_FILE_DIR, '..', '..'))
if _SRC_DIR not in sys.path:
    sys.path.insert(0, _SRC_DIR)
# --- ã“ã“ã¾ã§ ---

# --- ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from backend.services import gemini_service # gemini_serviceãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.workers.pitch_worker import PitchWorker
from backend.workers.sentiment_worker import SentimentWorker
# æ–°ã—ãä½œã£ãŸå…±é€šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.shared_config import RATE, CHUNK, CHANNELS, FORMAT, SAMPLE_WIDTH

# logging ã®åŸºæœ¬è¨­å®š (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ï¼‘å›ã ã‘å®Ÿè¡Œ)
# SpeechProcessor ã‚¯ãƒ©ã‚¹ã®å¤–ã§è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ã‚ˆã‚“ï¼
logging.basicConfig(
    level=logging.INFO,  # é–‹ç™ºä¸­ã¯INFOãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã‚’è¡¨ç¤º
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
# ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = logging.getLogger(__name__)

# --- SpeechProcessorã‚¯ãƒ©ã‚¹ã§Geminié–¢é€£ã®ã‚³ãƒ¼ãƒ‰ã‚’ç®¡ç†ã™ã‚‹ã®ã§ã€ã“ã“ã®é‡è¤‡ã¯å‰Šé™¤ï¼ ---

class SpeechProcessor:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã®ã‚¯ãƒ©ã‚¹ã ã‚ˆã‚“ï¼
    æ–‡å­—èµ·ã“ã—ã€éŸ³ç¨‹è§£æã€æ„Ÿæƒ…åˆ†æã€Geminiè©•ä¾¡ã‚’ã¾ã¨ã‚ã¦ã‚„ã‚‹ãï¼
    """

    def __init__(self):
        self.speech_client = speech.SpeechAsyncClient()
        self._audio_queue = asyncio.Queue()
        self._is_running = False
        self._processing_task = None # ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ä¿æŒã™ã‚‹
        self._microphone_task = None # æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä¿æŒã™ã‚‹
        self._stop_event = asyncio.Event()
        self.main_loop = asyncio.get_event_loop()
        self.pyaudio_instance = None
        self.microphone_stream = None
        self.send_to_client_callback = None # é€ä¿¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

        # PitchWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            self.pitch_worker = PitchWorker(
                sample_rate=RATE,
                channels=CHANNELS,
                sample_width=SAMPLE_WIDTH,
            )
            logger.info("ğŸµ PitchWorker ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± PitchWorker ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.pitch_worker = None

        # SentimentWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            # Google Cloud Natural Language API ã‚’ä½¿ã†ã®ã§ã€APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ã§è¨­å®šã•ã‚Œã¦ã‚‹å‰æã ã‚ˆã‚“ï¼
            self.sentiment_worker = SentimentWorker(
                on_emotion_callback=self._handle_emotion_data,
                language_code="ja" # Google Cloud NL API ã¯ "ja" ã‚’ä½¿ã†ã‚ˆï¼
            )
            logger.info("ğŸ˜Š SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e: # SentimentWorkerå†…ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã‚‚ã‚­ãƒ£ãƒƒãƒã§ãã‚‹ã‚ˆã†ã«æ±ç”¨çš„ãªExceptionã«
            logger.exception("ğŸ˜± SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.sentiment_worker = None

        logger.info("âœ¨ SpeechProcessor åˆæœŸåŒ–å®Œäº†ï¼âœ¨")
        logger.info(f"PyAudioè¨­å®š: FORMAT={FORMAT}, CHANNELS={CHANNELS}, RATE={RATE}, CHUNK={CHUNK}, SAMPLE_WIDTH={SAMPLE_WIDTH}")

        # --- Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®åˆæœŸåŒ– ---
        # gemini_service ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«åˆæœŸåŒ–ãŒèµ°ã‚‹ã‹ã‚‰ã€ã“ã“ã§ã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã ã‘ï¼
        self.gemini_enabled = gemini_service.gemini_model_instance is not None
        if self.gemini_enabled:
            logger.info("ğŸ‘‘ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸã€‚")
        else:
            logger.warning("ğŸ˜¢ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã¯ç„¡åŠ¹ã§ã™ã€‚è¨­å®šã¾ãŸã¯èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹å¤‰æ•°ã‚’åˆæœŸåŒ– ---
        self.current_interview_question = "è‡ªå·±PRã‚’ã—ã¦ãã ã•ã„ã€‚" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•
        self.full_transcript = "" # æ–‡å­—èµ·ã“ã—å…¨æ–‡ã‚’ä¿æŒ
        self.pitch_values = []    # ãƒ”ãƒƒãƒã®æ¸¬å®šå€¤ã‚’ä¿æŒ
        self.last_pitch_analysis_summary = {} # ãƒ”ãƒƒãƒè§£æã®é›†è¨ˆçµæœ
        self.last_emotion_analysis_summary = {} # æ„Ÿæƒ…åˆ†æã®é›†è¨ˆçµæœ
        # --- ã“ã“ã¾ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å¤‰æ•° ---

    async def process_audio_chunk(self, chunk: bytes):
        """
        WebSocketã‹ã‚‰å—ã‘å–ã£ãŸéŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚ˆã€‚
        ãƒ”ãƒƒãƒè§£æã¨ã€æ–‡å­—èµ·ã“ã—ã‚­ãƒ¥ãƒ¼ã¸ã®è¿½åŠ ã‚’è¡Œã†ã€‚
        """
        if not self._is_running:
            return

        # 1. ãƒ”ãƒƒãƒã‚’è§£æ
        if self.pitch_worker:
            pitch = self.pitch_worker.analyze_pitch(chunk)
            if pitch is not None:
                self.pitch_values.append(pitch)
                # logger.debug(f"ğŸ¤ æ¤œå‡ºã•ã‚ŒãŸãƒ”ãƒƒãƒ: {pitch:.2f} Hz") # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¾¿åˆ©

        # 2. æ–‡å­—èµ·ã“ã—ç”¨ã®ã‚­ãƒ¥ãƒ¼ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        await self._audio_queue.put(chunk)

    async def _start_workers(self):
        """æ„Ÿæƒ…åˆ†æãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•ã™ã‚‹ã‚ˆã‚“ï¼"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯èµ·å‹•ã—ãªã„
        if self.sentiment_worker:
            # startãŒéåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§awaitã™ã‚‹
            await self.sentiment_worker.start()

    async def _stop_workers(self):
        """æ„Ÿæƒ…åˆ†æãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ã™ã‚‹ã‚ˆã‚“ï¼"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯åœæ­¢ã—ãªã„
        if self.sentiment_worker:
            # stopãŒéåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§awaitã™ã‚‹
            await self.sentiment_worker.stop()

    def _get_pyaudio_instance(self):
        """PyAudioã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã¾ãŸã¯ç”Ÿæˆã™ã‚‹ã‚ˆã€‚ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆã®æ™‚ã ã‘ã­ï¼"""
        if self.pyaudio_instance is None:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒãªã„ã®ã§ã€æ–°ã—ãä½œã‚‹ã‚ˆï¼")
            try:
                self.pyaudio_instance = pyaudio.PyAudio()
                logger.info("ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆç”¨ã«PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ–°ã—ãä½œã£ãŸã‚ˆï¼")
            except Exception:
                # ã“ã“ã§ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚å‡ºåŠ›ã™ã‚‹
                logger.error("PyAudioã®åˆæœŸåŒ–ä¸­ã«ã‚¬ãƒãªã‚¨ãƒ©ãƒ¼ã§ã¡ã‚ƒã£ãŸâ€¦", exc_info=True)
                self.pyaudio_instance = None # å¤±æ•—ã—ãŸã‚‰Noneã«æˆ»ã™
        return self.pyaudio_instance

    def set_send_to_client_callback(self, callback):
        """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹ãŸã‚ã®éåŒæœŸã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’ã‚»ãƒƒãƒˆã™ã‚‹ã‚ˆ"""
        self.send_to_client_callback = callback

    async def _send_to_client(self, data_type, payload):
        """ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯çµŒç”±ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«JSONãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹"""
        if self.send_to_client_callback:
            message = {"type": data_type, "payload": payload}
            await self.send_to_client_callback(message)

    def _get_speech_client(self):
        # ... existing code ...
        pass

    def set_interview_question(self, question: str):
        """ç¾åœ¨ã®é¢æ¥ã®è³ªå•ã‚’è¨­å®šã™ã‚‹ã‚ˆã‚“ï¼"""
        self.current_interview_question = question
        logger.info(f"ğŸ¤ è¨­å®šã•ã‚ŒãŸé¢æ¥ã®è³ªå•: {question}")

    def _handle_emotion_data(self, emotion_data: dict):
        """
        SentimentWorkerã‹ã‚‰ã®æ„Ÿæƒ…åˆ†æçµæœã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã€‚
        Google Cloud Natural Language API ã®çµæœã«åˆã‚ã›ã¦èª¿æ•´ã—ãŸã‚ˆã‚“ï¼
        """
        # Natural Language API ã‹ã‚‰ã¯ score ã¨ magnitude ãŒãƒ¡ã‚¤ãƒ³ã§è¿”ã£ã¦ãã‚‹
        score = emotion_data.get("emotions", {}).get("score")
        magnitude = emotion_data.get("emotions", {}).get("magnitude")
        text_processed = emotion_data.get("text_processed", "")

        if score is not None and magnitude is not None:
            logger.info(f"ğŸ˜Š æ„Ÿæƒ…åˆ†æçµæœ (Google NL): ã‚¹ã‚³ã‚¢={score:.2f}, å¼·ã•={magnitude:.2f} (ãƒ†ã‚­ã‚¹ãƒˆ: '{text_processed[:50]}...')")
            # TODO: ã“ã®æƒ…å ±ã‚’ self.last_emotion_analysis_summary ã«é©åˆ‡ã«æ ¼ç´ã™ã‚‹
            # ä¾‹: self.last_emotion_analysis_summary = {"dominant_emotion": "è§£æãƒ­ã‚¸ãƒƒã‚¯", "score": score, "magnitude": magnitude, ...}
            # ä»Šå›ã¯å˜ç´”ã«æœ€æ–°ã®ã‚‚ã®ã‚’ä¿æŒã™ã‚‹ä¾‹
            self.last_emotion_analysis_summary = {
                "dominant_emotion": "ä¸æ˜ (Google NL score/magnitudeãƒ™ãƒ¼ã‚¹)",
                "emotion_score": score,
                "emotion_intensity": magnitude,
                "emotion_transition": "N/A (Google NLã¯ç™ºè©±å…¨ä½“)" # Google NLã®åŸºæœ¬APIã§ã¯æ¨ç§»ã¯å–ã‚Œãªã„
            }
        else:
            logger.warning(f"ğŸ¤” æ„Ÿæƒ…åˆ†æçµæœãŒä¸å®Œå…¨ã§ã™: {emotion_data}")

    async def _process_speech_stream(self):
        """
        ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Googleã«é€ã‚Šã€çµæœã‚’å‡¦ç†ã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã ã‚ˆã‚“ï¼
        WebSocketã‹ã‚‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ç”¨ã«èª¿æ•´ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
        """
        try:
            # 1. Google Speech-to-Text APIã«æ¥ç¶šã—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šã‚’é€ä¿¡
            stream_generator = self._microphone_stream_generator()
            # streaming_recognizeã¯ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’è¿”ã™ã‚³ãƒ«ãƒ¼ãƒãƒ³ãªã®ã§ã€awaitã§è§£æ±ºã™ã‚‹
            responses_iterator = await self.speech_client.streaming_recognize(requests=stream_generator)
            logger.info("âœ… Google Speech-to-Text APIã¨ã®æ¥ç¶šå®Œäº†ï¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹å¾…æ©Ÿä¸­...")

            # 2. ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹
            await self._start_workers()

            # 3. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’éåŒæœŸã§å‡¦ç†
            async for response in responses_iterator:
                if not self._is_running:
                    logger.info("is_runningãŒFalseã«ãªã£ãŸãŸã‚ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                    break

                # --- ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’å‡ºåŠ› ---
                # logger.debug(f"Googleã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {response}")

                if not response.results:
                    continue

                result = response.results[0]
                if not result.alternatives:
                    continue

                transcript = result.alternatives[0].transcript
                
                # ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
                if self.sentiment_worker:
                    await self.sentiment_worker.add_text(transcript)

                if result.is_final:
                    logger.info(f"âœ… ç¢ºå®šã—ãŸæ–‡å­—èµ·ã“ã—: {transcript}")
                    # å…¨æ–‡æ–‡å­—èµ·ã“ã—ã‚’æ›´æ–°
                    self.full_transcript += transcript + " "
                    await self._send_to_client(
                        "final_transcript_segment", 
                        {"transcript": transcript}
                    )
                else:
                    # logger.info(f"ğŸ’¬ ä»®ã®æ–‡å­—èµ·ã“ã—: {transcript}")
                    await self._send_to_client(
                        "interim_transcript",
                        {"transcript": transcript}
                    )
        except asyncio.CancelledError:
            logger.info("ğŸš« _process_speech_stream ã‚¿ã‚¹ã‚¯ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ã¯é€Ÿã‚„ã‹ã«çµ‚äº†
            raise
        except StopAsyncIteration:
             logger.info("ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸã€‚")
        except exceptions.OutOfRange as e:
            # éŸ³å£°ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã‚’ã“ã“ã§ã‚­ãƒ£ãƒƒãƒï¼
            logger.error(f"ğŸ˜± éŸ³å£°ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            await self._send_to_client("error", {"message": "é•·æ™‚é–“éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"})
        except Exception as e:
            logger.error(f"ğŸ˜± _process_speech_streamã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼: {e}", exc_info=True)
            await self._send_to_client("error", {"message": f"éŸ³å£°å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"})
        finally:
            logger.info("ğŸ _process_speech_stream ãƒ«ãƒ¼ãƒ—ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚")
            # ã“ã“ã§ã¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’æ­¢ã‚ãªã„ã€‚stop_transcription_and_evaluationã§åˆ¶å¾¡ã™ã‚‹ã€‚

    async def _microphone_stream_generator(self):
        """
        ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’éåŒæœŸã§ä¾›çµ¦ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã ã‚ˆã‚“ï¼
        Speech-to-Text API ãŒæœŸå¾…ã™ã‚‹ StreamingRecognitionConfig ã¨éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ yield ã™ã‚‹ã€‚
        """
        streaming_config = speech.StreamingRecognitionConfig(
            config=speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=RATE,
                language_code="ja-JP",
                enable_automatic_punctuation=True,
            ),
            interim_results=True,
        )
        yield speech.StreamingRecognizeRequest(streaming_config=streaming_config)
        logger.info("ğŸ¤ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šé€ä¿¡å®Œäº†ï¼éŸ³å£°å¾…æ©Ÿä¸­...")

        while self._is_running and not self._stop_event.is_set():
            try:
                chunk = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                if chunk is None: 
                    logger.info("ã‚­ãƒ¥ãƒ¼ã‹ã‚‰Noneã‚’å—ã‘å–ã£ãŸã®ã§ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                
                # --- PitchWorkerã®å‡¦ç†ã‚’ã“ã“ã«ç§»å‹•ã—ãªã„ ---
                # ã“ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¯Speech-to-Text APIã«ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹ã“ã¨ã«å°‚å¿µã™ã‚‹
                # ãƒ”ãƒƒãƒè§£æã¯ process_audio_chunk ã§è¡Œã‚ã‚Œã‚‹
                
                yield speech.StreamingRecognizeRequest(audio_content=chunk)
            except asyncio.TimeoutError:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯æƒ³å®šå†…ã®å‹•ä½œãªã®ã§ã€ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’DEBUGã«
                # logger.debug("ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã®å¾…æ©ŸãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã¸ã€‚")
                continue
            except asyncio.CancelledError:
                logger.info("ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
                break
            except Exception as e:
                logger.error(f"ğŸ˜± _microphone_stream_generatorã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                break
        logger.info("ğŸ¤ _microphone_stream_generator çµ‚äº†")

    def _microphone_worker(self):
        """
        PyAudioã§ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã—ã€ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•° (ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ)ã€‚
        ã“ã‚Œã¯æ‰‹å‹•ãƒ†ã‚¹ãƒˆ (`manual_test_speech_processor.py`) ã®ãŸã‚ã®ã‚‚ã®ã ã‚ˆã‚“ï¼
        """
        p = self._get_pyaudio_instance()
        if not p:
            logger.error("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã€‚")
            return

        try:
            self.microphone_stream = p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
                stream_callback=self._microphone_callback
            )
            logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ãã¾ã—ãŸã€‚éŒ²éŸ³é–‹å§‹ï¼")

            while self.microphone_stream.is_active() and self._is_running:
                time.sleep(0.1)

        except Exception as e:
            logger.error(f"ğŸ˜± ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚ªãƒ¼ãƒ—ãƒ³ã¾ãŸã¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        finally:
            if self.microphone_stream:
                self.microphone_stream.stop_stream()
                self.microphone_stream.close()
                self.microphone_stream = None
                logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ãƒ»ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸã€‚")
            # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®çµ‚äº†ã¯ __del__ ã§è¡Œã†
            # p.terminate()

    def _microphone_callback(self, in_data, frame_count, time_info, status):
        """ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        # ã“ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã®ã§ã€éåŒæœŸã®putã§ã¯ãªãput_nowaitã‚’ä½¿ã†
        try:
            # process_audio_chunkã‚’ç›´æ¥å‘¼ã³å‡ºã™ã“ã¨ã§ãƒ”ãƒƒãƒè§£æã‚‚å®Ÿè¡Œ
            # ãŸã ã—ã€asyncé–¢æ•°ãªã®ã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã³å‡ºã™ã«ã¯å·¥å¤«ãŒå¿…è¦
            # ã“ã“ã§ã¯ event_loop ã‚’ä½¿ã£ã¦ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã™ã‚‹
            asyncio.run_coroutine_threadsafe(
                self.process_audio_chunk(in_data),
                self.main_loop
            )
        except Exception as e:
            logger.error(f"ãƒã‚¤ã‚¯ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã®ã‚­ãƒ¥ãƒ¼è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        return (in_data, pyaudio.paContinue)


    async def start_transcription_and_evaluation(self):
        """
        WebSocketã‹ã‚‰ã®éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ã‘ä»˜ã‘ã‚‹ãŸã‚ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ğŸ–¥ï¸ ã™ã§ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
            return

        logger.info("ğŸš€ WebSocketã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._stop_event.clear()
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ ---
        self.full_transcript = ""
        self.pitch_values = []
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        # --- ã“ã“ã¾ã§ ---

        self._processing_task = asyncio.create_task(self._process_speech_stream())
        logger.info("ğŸ”¥ ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")

    async def start_realtime_transcription_from_mic(self):
        """
        ã€æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã€‘ãƒã‚¤ã‚¯ã‹ã‚‰ç›´æ¥éŸ³å£°ã‚’å–å¾—ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ğŸ™ï¸ ã™ã§ã«ãƒã‚¤ã‚¯ã‹ã‚‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
            return
        
        logger.info("ğŸš€ ãƒã‚¤ã‚¯ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._stop_event.clear()
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ ---
        self.full_transcript = ""
        self.pitch_values = []
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        # --- ã“ã“ã¾ã§ ---

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚’å–å¾—
        self.main_loop = asyncio.get_running_loop()

        # ãƒã‚¤ã‚¯å…¥åŠ›ç”¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        self._microphone_task = threading.Thread(target=self._microphone_worker, daemon=True)
        self._microphone_task.start()
        
        # Speech-to-Textã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self._processing_task = asyncio.create_task(self._process_speech_stream())
        logger.info("ğŸ”¥ ãƒã‚¤ã‚¯éŸ³å£°ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")


    async def stop_transcription_and_evaluation(self):
        """
        æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åœæ­¢ã—ã€æœ€çµ‚è©•ä¾¡ã‚’å–å¾—ã™ã‚‹ã‚ˆã‚“ï¼
        """
        logger.info("â³ æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã®å‡¦ç†ã‚’åœæ­¢ä¸­...")

        if not self._is_running:
            logger.warning("ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¯ã™ã§ã«åœæ­¢ã—ã¦ã„ã¾ã™ã€‚")
            return

        self._is_running = False
        self._stop_event.set()

        # ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’åœæ­¢
        # ãƒã‚¤ã‚¯ç”¨ã®ã‚­ãƒ¥ãƒ¼ã«Noneã‚’å…¥ã‚Œã¦ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’æ­¢ã‚ã‚‹
        if self._audio_queue:
            await self._audio_queue.put(None)

        # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤
        if self._processing_task:
            try:
                await asyncio.wait_for(self._processing_task, timeout=5.0)
            except asyncio.TimeoutError:
                logger.warning("âŒ› _processing_task ã®åœæ­¢ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
                self._processing_task.cancel()
            except Exception as e:
                logger.error(f"ğŸ˜± _processing_task åœæ­¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        
        # ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã®åœæ­¢ï¼ˆæ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ï¼‰
        if self._microphone_task and self._microphone_task.is_alive():
            # ã“ã®éƒ¨åˆ†ã¯æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ãªã®ã§ã€WebSocketçµŒç”±ã§ã¯ç›´æ¥å‘¼ã°ã‚Œãªã„
            logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿä¸­...")
            # _microphone_workerå†…ã®ãƒ«ãƒ¼ãƒ—ã¯_is_runningãƒ•ãƒ©ã‚°ã§çµ‚äº†ã™ã‚‹ã¯ãš
            self._microphone_task.join(timeout=3.0)
            if self._microphone_task.is_alive():
                logger.warning("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")


        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢
        await self._stop_workers()
        logger.info("âœ… ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
        
        # --- æœ€çµ‚è©•ä¾¡ã®å®Ÿè¡Œ ---
        if self.gemini_enabled:
            logger.info("â³æœ€çµ‚è©•ä¾¡ã‚’Geminiã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")
            
            # ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
            self._summarize_pitch_data()

            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«è©•ä¾¡ä¸­ã§ã‚ã‚‹ã“ã¨ã‚’é€šçŸ¥
            await self._send_to_client("evaluation_started", {})
            
            try:
                final_evaluation = await gemini_service.get_gemini_evaluation(
                    interview_question=self.current_interview_question,
                    transcript=self.full_transcript.strip(),
                    pitch_analysis=self.last_pitch_analysis_summary,
                    emotion_analysis=self.last_emotion_analysis_summary,
                )
                logger.info(f"ğŸ‘‘ Geminiã‹ã‚‰ã®æœ€çµ‚è©•ä¾¡:\n{final_evaluation}")

                # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«æœ€çµ‚è©•ä¾¡ã‚’é€ä¿¡
                await self._send_to_client(
                    "final_evaluation",
                    {"evaluation": final_evaluation}
                )

            except Exception as e:
                logger.error(f"ğŸ˜± Geminiã¸ã®è©•ä¾¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
                await self._send_to_client(
                    "error",
                    {"message": f"Geminiè©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"}
                )
        else:
            logger.warning("ğŸ˜¢ Geminiè©•ä¾¡ã¯ç„¡åŠ¹ãªãŸã‚ã€æœ€çµ‚è©•ä¾¡ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")

        logger.info("âœ… ã™ã¹ã¦ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

        # ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self._stop_event.clear()
        self._processing_task = None
        self._microphone_task = None
        # ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹
        while not self._audio_queue.empty():
            self._audio_queue.get_nowait()
            
    def _summarize_pitch_data(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã«åé›†ã—ãŸãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’è¦ç´„ã—ã¦ã€last_pitch_analysis_summaryã‚’æ›´æ–°ã™ã‚‹"""
        if not self.pitch_values:
            logger.info("ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ãŒåé›†ã•ã‚Œãªã‹ã£ãŸã®ã§ã€ãƒ”ãƒƒãƒã®è¦ç´„ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            self.last_pitch_analysis_summary = {
                "average_pitch": "ãƒ‡ãƒ¼ã‚¿ãªã—",
                "pitch_variation": "ãƒ‡ãƒ¼ã‚¿ãªã—",
                "pitch_stability": "ãƒ‡ãƒ¼ã‚¿ãªã—",
                "min_pitch": "ãƒ‡ãƒ¼ã‚¿ãªã—",
                "max_pitch": "ãƒ‡ãƒ¼ã‚¿ãªã—",
            }
            return

        try:
            import numpy as np
            
            # NumPyé…åˆ—ã«å¤‰æ›
            pitch_array = np.array(self.pitch_values)
            
            # å¹³å‡ãƒ”ãƒƒãƒ
            avg_pitch = np.mean(pitch_array)
            # ãƒ”ãƒƒãƒã®æ¨™æº–åå·®ï¼ˆå¤‰å‹•ï¼‰
            std_dev_pitch = np.std(pitch_array)
            # ãƒ”ãƒƒãƒã®å®‰å®šæ€§ï¼ˆå¤‰å‹•ä¿‚æ•°ï¼‰ - å¹³å‡ã«å¯¾ã™ã‚‹å¤‰å‹•ã®å‰²åˆ
            # avg_pitchãŒ0ã®å ´åˆã®ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
            cv_pitch = (std_dev_pitch / avg_pitch) * 100 if avg_pitch > 0 else 0
            # æœ€å°ãƒ»æœ€å¤§ãƒ”ãƒƒãƒ
            min_pitch = np.min(pitch_array)
            max_pitch = np.max(pitch_array)

            self.last_pitch_analysis_summary = {
                "average_pitch": f"{avg_pitch:.2f} Hz",
                "pitch_variation": f"{std_dev_pitch:.2f} Hz (æ¨™æº–åå·®)",
                "pitch_stability": f"{cv_pitch:.2f} % (å¤‰å‹•ä¿‚æ•°)",
                "min_pitch": f"{min_pitch:.2f} Hz",
                "max_pitch": f"{max_pitch:.2f} Hz",
            }
            logger.info(f"ğŸ¤ ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®è¦ç´„å®Œäº†: {self.last_pitch_analysis_summary}")

        except ImportError:
            logger.warning("NumPyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ”ãƒƒãƒã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
            self.last_pitch_analysis_summary = {"error": "NumPy not found"}
        except Exception as e:
            logger.error(f"ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            self.last_pitch_analysis_summary = {"error": str(e)}


    def __del__(self):
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒç ´æ£„ã•ã‚Œã‚‹ã¨ãã«PyAudioã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.pyaudio_instance:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£æ”¾ã—ã¾ã™ã€‚")
            self.pyaudio_instance.terminate()
            self.pyaudio_instance = None