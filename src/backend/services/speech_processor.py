# ã“ã“ã« Google Cloud Speech-to-Text ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹æ„Ÿã˜ã§ï¼
from google.cloud import speech_v1p1beta1 as speech # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ã†ã‚ˆï¼
from google.api_core import exceptions
import asyncio
import pyaudio
import logging # logging ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os # ç’°å¢ƒå¤‰æ•°ã®ãŸã‚ã«è¿½åŠ 
import time
import threading
from google.cloud import pubsub_v1 # â—€ï¸ Pub/Subãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
import json
import uuid # â—€ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆã®ãŸã‚ã«è¿½åŠ ï¼

# --- Pythonã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œç´¢ãƒ‘ã‚¹ã«srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ  ---
import sys
# speech_processor.py ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (src/backend/services)
_CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ (src/backend/services -> src/backend -> src)
_SRC_DIR = os.path.abspath(os.path.join(_CURRENT_FILE_DIR, '..', '..'))
if _SRC_DIR not in sys.path:
    sys.path.insert(0, _SRC_DIR)
# --- ã“ã“ã¾ã§ ---

# --- ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from backend.services import gemini_service # gemini_serviceãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.workers.pitch_worker import PitchWorker
from backend.services import dialogflow_service # â—€ï¸ sentiment_worker ã®ä»£ã‚ã‚Šã« dialogflow_service ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
# æ–°ã—ãä½œã£ãŸå…±é€šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.shared_config import RATE, CHUNK, CHANNELS, FORMAT, SAMPLE_WIDTH

# logging ã®åŸºæœ¬è¨­å®š (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ï¼‘å›ã ã‘å®Ÿè¡Œ)
# SpeechProcessor ã‚¯ãƒ©ã‚¹ã®å¤–ã§è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ã‚ˆã‚“ï¼
logging.basicConfig(
    level=logging.INFO,  # é–‹ç™ºä¸­ã¯INFOãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã‚’è¡¨ç¤º
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
# ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = logging.getLogger(__name__)

# --- Pub/Subé–¢é€£ã®å®šæ•° ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹ã®ãŒã‚¤ã‚±ã¦ã‚‹ã‘ã©ã€ã¾ãšã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã§ã€‚å¾Œã§ç›´ã™ï¼
# TODO: GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã¨ãƒˆãƒ”ãƒƒã‚¯åã‚’å…±é€šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ã™ã‚‹
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID", "your-gcp-project-id")
TRANSCRIPTION_TOPIC = "ep-x-transcriptions"

# --- SpeechProcessorã‚¯ãƒ©ã‚¹ã§Geminié–¢é€£ã®ã‚³ãƒ¼ãƒ‰ã‚’ç®¡ç†ã™ã‚‹ã®ã§ã€ã“ã“ã®é‡è¤‡ã¯å‰Šé™¤ï¼ ---

class SpeechProcessor:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã®ã‚¯ãƒ©ã‚¹ã ã‚ˆã‚“ï¼
    æ–‡å­—èµ·ã“ã—ã€éŸ³ç¨‹è§£æã€æ„Ÿæƒ…åˆ†æã€Geminiè©•ä¾¡ã‚’ã¾ã¨ã‚ã¦ã‚„ã‚‹ãï¼
    """

    def __init__(self):
        self.speech_client = speech.SpeechAsyncClient()
        self._audio_queue = asyncio.Queue()
        self._is_running = False
        self._processing_task = None # ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ä¿æŒã™ã‚‹
        self._microphone_task = None # æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä¿æŒã™ã‚‹
        self._stop_event = asyncio.Event()
        self.main_loop = asyncio.get_event_loop()
        self.pyaudio_instance = None
        self.microphone_stream = None
        self.send_to_client_callback = None # é€ä¿¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        self.session_id = str(uuid.uuid4()) # â—€ï¸ å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªIDã‚’ç”Ÿæˆï¼

        # --- Pub/Sub Publisherã®åˆæœŸåŒ– ---
        try:
            self.publisher = pubsub_v1.PublisherClient()
            self.topic_path = self.publisher.topic_path(GCP_PROJECT_ID, TRANSCRIPTION_TOPIC)
            logger.info(f"âœ… Pub/Sub Publisherã®åˆæœŸåŒ–å®Œäº†ï¼ãƒˆãƒ”ãƒƒã‚¯: {self.topic_path}")
        except Exception as e:
            logger.exception("ğŸ˜± Pub/Sub Publisher ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.publisher = None
            self.topic_path = None
        # --- ã“ã“ã¾ã§Pub/SubåˆæœŸåŒ– ---

        # PitchWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            self.pitch_worker = PitchWorker(
                sample_rate=RATE,
                channels=CHANNELS,
                sample_width=SAMPLE_WIDTH,
            )
            logger.info("ğŸµ PitchWorker ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± PitchWorker ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.pitch_worker = None

        logger.info("âœ¨ SpeechProcessor åˆæœŸåŒ–å®Œäº†ï¼âœ¨")
        logger.info(f"PyAudioè¨­å®š: FORMAT={FORMAT}, CHANNELS={CHANNELS}, RATE={RATE}, CHUNK={CHUNK}, SAMPLE_WIDTH={SAMPLE_WIDTH}")

        # --- Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®åˆæœŸåŒ– ---
        # gemini_service ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«åˆæœŸåŒ–ãŒèµ°ã‚‹ã‹ã‚‰ã€ã“ã“ã§ã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã ã‘ï¼
        self.gemini_enabled = gemini_service.gemini_model_instance is not None
        if self.gemini_enabled:
            logger.info("ğŸ‘‘ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸã€‚")
        else:
            logger.warning("ğŸ˜¢ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã¯ç„¡åŠ¹ã§ã™ã€‚è¨­å®šã¾ãŸã¯èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹å¤‰æ•°ã‚’åˆæœŸåŒ– ---
        self.current_interview_question = "è‡ªå·±PRã‚’ã—ã¦ãã ã•ã„ã€‚" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•
        self.full_transcript = "" # æ–‡å­—èµ·ã“ã—å…¨æ–‡ã‚’ä¿æŒ
        self.pitch_values = []    # ãƒ”ãƒƒãƒã®æ¸¬å®šå€¤ã‚’ä¿æŒ
        self.last_pitch_analysis_summary = {} # ãƒ”ãƒƒãƒè§£æã®é›†è¨ˆçµæœ
        self.last_emotion_analysis_summary = {} # æ„Ÿæƒ…åˆ†æã®é›†è¨ˆçµæœ
        
        # --- ãƒ”ãƒƒãƒè§£æç”¨ã®ãƒãƒƒãƒ•ã‚¡ã¨è¨­å®šã‚’è¿½åŠ  ---
        self._pitch_buffer = b""
        self._required_pitch_bytes = 0
        if self.pitch_worker:
            # pitch_workerãŒå¿…è¦ã¨ã™ã‚‹æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°(max_lag)ã®2å€ã‚’ãƒã‚¤ãƒˆæ•°ã§è¨ˆç®—
            # 2å€ã«ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå®‰å®šã—ãŸè§£æãŒæœŸå¾…ã§ãã‚‹
            # ä¾‹: 16000Hz / 50Hz(min_freq) = 320ã‚µãƒ³ãƒ—ãƒ« -> 320 * 2(bytes) * 2 = 1280ãƒã‚¤ãƒˆ
            self._required_pitch_bytes = self.pitch_worker.max_lag * self.pitch_worker.sample_width * 2
            logger.info(f"ãƒ”ãƒƒãƒè§£æã«å¿…è¦ãªæœ€å°ãƒã‚¤ãƒˆæ•°: {self._required_pitch_bytes}")
        # --- ã“ã“ã¾ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å¤‰æ•° ---

    async def process_audio_chunk(self, chunk: bytes):
        """
        WebSocketã‹ã‚‰å—ã‘å–ã£ãŸéŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚ˆã€‚
        ãƒ”ãƒƒãƒè§£æã€æ„Ÿæƒ…åˆ†æã€æ–‡å­—èµ·ã“ã—ã‚­ãƒ¥ãƒ¼ã¸ã®è¿½åŠ ã‚’è¡Œã†ã€‚
        """
        if not self._is_running:
            return

        # 1. ãƒ”ãƒƒãƒã‚’è§£æ
        if self.pitch_worker and self._required_pitch_bytes > 0:
            self._pitch_buffer += chunk

            # ãƒãƒƒãƒ•ã‚¡ãŒååˆ†ãªå¤§ãã•ã«ãªã£ãŸã‚‰è§£æ
            if len(self._pitch_buffer) >= self._required_pitch_bytes:
                pitch = self.pitch_worker.analyze_pitch(self._pitch_buffer)
                
                if pitch is not None:
                    # æœ€çµ‚è©•ä¾¡ç”¨ã«è“„ç©
                    self.pitch_values.append(pitch)
                    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡ï¼
                    timestamp = time.time()
                    await self._send_to_client(
                        "pitch_analysis",
                        {"pitch": pitch, "timestamp": timestamp}
                    )
                
                # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¹ãƒ©ã‚¤ãƒ‰ã•ã›ã‚‹ (å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤)
                # ä»Šå›ã¯è§£æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®åŠåˆ†ã‚’å‰Šé™¤ã—ã¦ã€æ¬¡ã®è§£æã¨ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã•ã›ã‚‹
                slide_bytes = self._required_pitch_bytes // 2
                self._pitch_buffer = self._pitch_buffer[slide_bytes:]

        # 2. Symbl.aiã¸ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ã¯ä¸è¦ã«ãªã£ãŸã®ã§å‰Šé™¤ï¼

        # 3. æ–‡å­—èµ·ã“ã—ç”¨ã®ã‚­ãƒ¥ãƒ¼ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if not self._stop_event.is_set():
            await self._audio_queue.put(chunk)

    async def _start_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã®èµ·å‹•å‡¦ç†ï¼ˆç¾åœ¨ã¯ç©ºï¼‰"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯èµ·å‹•ã—ãªã„
        # SentimentWorkerã‚‚ã„ãªããªã£ãŸã®ã§ã€ã“ã“ã¯ç©ºã£ã½ï¼
        pass

    async def _stop_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åœæ­¢å‡¦ç†ï¼ˆç¾åœ¨ã¯ç©ºï¼‰"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯åœæ­¢ã—ãªã„
        # SentimentWorkerã‚‚ã„ãªããªã£ãŸã®ã§ã€ã“ã“ã¯ç©ºã£ã½ï¼
        pass

    def _get_pyaudio_instance(self):
        """PyAudioã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã¾ãŸã¯ç”Ÿæˆã™ã‚‹ã‚ˆã€‚ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆã®æ™‚ã ã‘ã­ï¼"""
        if self.pyaudio_instance is None:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒãªã„ã®ã§ã€æ–°ã—ãä½œã‚‹ã‚ˆï¼")
            try:
                self.pyaudio_instance = pyaudio.PyAudio()
                logger.info("ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆç”¨ã«PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ–°ã—ãä½œã£ãŸã‚ˆï¼")
            except Exception:
                # ã“ã“ã§ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚å‡ºåŠ›ã™ã‚‹
                logger.error("PyAudioã®åˆæœŸåŒ–ä¸­ã«ã‚¬ãƒãªã‚¨ãƒ©ãƒ¼ã§ã¡ã‚ƒã£ãŸâ€¦", exc_info=True)
                self.pyaudio_instance = None # å¤±æ•—ã—ãŸã‚‰Noneã«æˆ»ã™
        return self.pyaudio_instance

    def set_send_to_client_callback(self, callback):
        """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹ãŸã‚ã®éåŒæœŸã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’ã‚»ãƒƒãƒˆã™ã‚‹ã‚ˆ"""
        self.send_to_client_callback = callback

    async def _send_to_client(self, data_type, payload):
        """ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯çµŒç”±ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«JSONãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹"""
        if self.send_to_client_callback:
            message = {"type": data_type, "payload": payload}
            await self.send_to_client_callback(message)

    def _get_speech_client(self):
        # ... existing code ...
        pass

    def set_interview_question(self, question: str):
        """ç¾åœ¨ã®é¢æ¥ã®è³ªå•ã‚’è¨­å®šã™ã‚‹ã‚ˆã‚“ï¼"""
        self.current_interview_question = question
        logger.info(f"ğŸ¤ è¨­å®šã•ã‚ŒãŸé¢æ¥ã®è³ªå•: {question}")

    # --- Symbl.aiç”¨ã® _handle_emotion_data ã¯ä¸è¦ã«ãªã£ãŸã®ã§å®Œå…¨ã«å‰Šé™¤ï¼ ---

    async def _publish_to_pubsub(self, message_data: dict):
        """
        æ–‡å­—èµ·ã“ã—çµæœãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’Pub/Subã«éåŒæœŸã§é€ä¿¡ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if not self.publisher or not self.topic_path:
            logger.error("Pub/Sub PublisherãŒåˆæœŸåŒ–ã•ã‚Œã¦ãªã„ãŸã‚ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã§ãã¾ã›ã‚“ã€‚")
            return

        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã®ãƒã‚¤ãƒˆæ–‡å­—åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            data = json.dumps(message_data, ensure_ascii=False).encode("utf-8")
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ‘ãƒ–ãƒªãƒƒã‚·ãƒ¥ï¼
            future = self.publisher.publish(self.topic_path, data)
            # é€ä¿¡çµæœã‚’å¾…ã¤ï¼ˆéåŒæœŸãªã®ã§ã€ã“ã“ã§ã¯å¾…ãŸãšã«ãƒ­ã‚°ã ã‘å‡ºã™ï¼‰
            future.add_done_callback(lambda f: logger.info(f"ğŸ“¤ Pub/Subã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å®Œäº†: {f.result()}"))
            # await future # ã“ã“ã§å¾…ã¤ã¨ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã—ã¡ã‚ƒã†ã®ã§æ³¨æ„ï¼
        except exceptions.GoogleAPICallError as e:
            logger.error(f"ğŸ˜± Pub/Subã¸ã®é€ä¿¡ä¸­ã«APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        except Exception as e:
            logger.exception("ğŸ˜± Pub/Subã¸ã®é€ä¿¡ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

    async def _process_speech_stream(self):
        """
        éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†ã—ã¦ã€æ–‡å­—èµ·ã“ã—ã¨å„ç¨®åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã ã‚ˆã‚“ã€‚
        """
        try:
            # --- 1. éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ç”Ÿæˆ ---
            audio_stream_generator = self._audio_stream_generator()

            # --- 2. Google Cloud Speech-to-Text APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®š ---
            # ...ï¼ˆä¸­ç•¥ï¼‰...
            recognition_config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=RATE,
                language_code="ja-JP",
                enable_automatic_punctuation=True,
                profanity_filter=True, # ä¸é©åˆ‡ãªå˜èªã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            )
            streaming_config = speech.StreamingRecognitionConfig(
                config=recognition_config,
                interim_results=True, # æš«å®šçš„ãªçµæœã‚‚å—ã‘å–ã‚‹
            )

            # --- 3. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆã¨å®Ÿè¡Œ ---
            requests = (
                speech.StreamingRecognizeRequest(audio_content=chunk)
                for chunk in audio_stream_generator
            )

            logger.info("ğŸš€ Google Speech-to-Text APIã¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
            # recognizeãƒ¡ã‚½ãƒƒãƒ‰ã¯éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’è¿”ã™ï¼
            stream = await self.speech_client.streaming_recognize(
                requests=requests,
                config=streaming_config,
            )

            # --- 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç† ---
            async for response in stream:
                if not self._is_running:
                    break

                if not response.results:
                    continue

                result = response.results[0]
                if not result.alternatives:
                    continue
                
                transcript = result.alternatives[0].transcript
                timestamp = time.time()

                if result.is_final:
                    logger.info(f"âœ… æœ€çµ‚çš„ãªæ–‡å­—èµ·ã“ã—çµæœ: '{transcript}'")
                    self.full_transcript += transcript + " "
                    
                    # --- ğŸ”½ ã“ã“ã‹ã‚‰ãŒæ–°ã—ã„å‡¦ç†ï¼ ğŸ”½ ---
                    # 1. æœ€çµ‚çµæœã‚’Pub/Subã«é€ä¿¡ï¼ˆã“ã‚Œã¯ã‚‚ã¨ã‚‚ã¨ã‚ã£ãŸå‡¦ç†ï¼‰
                    pubsub_message = {
                        "text": transcript,
                        "timestamp": timestamp,
                        "session_id": self.session_id
                    }
                    await self._publish_to_pubsub(pubsub_message)

                    # 2. Dialogflowã§æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œï¼
                    logger.info(f"ğŸ¤– Dialogflowã«æ„Ÿæƒ…åˆ†æã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: '{transcript}'")
                    sentiment_result = dialogflow_service.analyze_sentiment(
                        session_id=self.session_id,
                        text=transcript
                    )
                    
                    if sentiment_result:
                        logger.info(f"ğŸ˜Š Dialogflowã‹ã‚‰ã®æ„Ÿæƒ…åˆ†æçµæœ: {sentiment_result}")
                        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«é€ä¿¡
                        await self._send_to_client("sentiment_analysis", sentiment_result)
                        # æœ€çµ‚è©•ä¾¡ç”¨ã«ä¿å­˜
                        self.last_emotion_analysis_summary = {
                            "score": sentiment_result.get("score"),
                            "magnitude": sentiment_result.get("magnitude")
                        }
                    else:
                        logger.warning("ğŸ˜¢ Dialogflowã§ã®æ„Ÿæƒ…åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    # --- ğŸ”¼ ã“ã“ã¾ã§ãŒæ–°ã—ã„å‡¦ç†ï¼ ğŸ”¼ ---

                else:
                    # æš«å®šçš„ãªçµæœã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
                    await self._send_to_client(
                        "interim_transcript",
                        {"text": transcript, "timestamp": timestamp}
                    )

        except exceptions.Cancelled as e:
            logger.warning("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã¯æ­£å¸¸ãªåœæ­¢å‡¦ç†ã®ä¸€éƒ¨ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        except exceptions.OutOfRange as e:
            logger.error(f"ğŸ˜± éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®çµ‚ç«¯ã«é”ã—ã¾ã—ãŸ: {e}")
        except exceptions.GoogleAPICallError as e:
            logger.error(f"ğŸ˜± Google Speech APIã®å‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            logger.exception("ğŸ˜± _process_speech_streamã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        finally:
            logger.info("ğŸ‘‹ _process_speech_stream ãƒ«ãƒ¼ãƒ—ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚")
            self._stop_event.set()

    async def _audio_stream_generator(self):
        """
        _audio_queueã‹ã‚‰éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å–ã‚Šå‡ºã—ã¦ã€Google APIã«é€ã‚Œã‚‹å½¢å¼ã§yieldã™ã‚‹éåŒæœŸã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã€‚
        """
        # 1. æœ€åˆã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šã‚’é€ä¿¡
        recognition_config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=RATE,
            language_code="ja-JP",
            enable_automatic_punctuation=True,
            # ãƒ¢ãƒ‡ãƒ«é¸æŠ: 'telephony'ã‹'medical_conversation'ãªã©ãŒç”¨é€”ã«åˆã‚ã›ã¦é¸ã¹ã‚‹
            # 'default' ã‚‚ã‚ã‚‹ã‘ã©ã€ä»Šå›ã¯æ±ç”¨çš„ãª 'latest_long' ã‚’è©¦ã—ã¦ã¿ã‚‹
            model="latest_long", 
            use_enhanced=True, # é«˜åº¦ãªéŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’æœ‰åŠ¹åŒ–
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=recognition_config,
            interim_results=True,  # é€”ä¸­çµæœã‚’å–å¾—ã™ã‚‹
            single_utterance=False # è¤‡æ•°å›ã®ç™ºè©±ã‚’èªè­˜
        )
        yield speech.StreamingRecognizeRequest(streaming_config=streaming_config)
        logger.info("ğŸ¤ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šé€ä¿¡å®Œäº†ï¼éŸ³å£°å¾…æ©Ÿä¸­...")

        # 2. ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã£ã¦é€ä¿¡
        while self._is_running and not self._stop_event.is_set():
            try:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                chunk = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                yield speech.StreamingRecognizeRequest(audio_content=chunk)
            except asyncio.TimeoutError:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯ã‚¨ãƒ©ãƒ¼ã˜ã‚ƒãªã„ã€‚ãƒ‡ãƒ¼ã‚¿ãŒæ¥ã¦ãªã„ã ã‘ã ã‹ã‚‰ãƒ«ãƒ¼ãƒ—ã‚’ç¶šã‘ã‚‹
                continue
            except asyncio.CancelledError:
                logger.info("ğŸ¤ _audio_stream_generatorãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
                break
        
        logger.info("ğŸ¤ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãŒçµ‚äº†ã—ã¾ã™ã€‚")

    def _microphone_worker(self):
        """
        PyAudioã‚’ä½¿ã£ã¦ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã—ã€éåŒæœŸã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•°ã€‚
        ã“ã‚Œã¯æ‰‹å‹•ãƒ†ã‚¹ãƒˆ (`manual_test_speech_processor.py`) ã®ãŸã‚ã®ã‚‚ã®ã ã‚ˆã‚“ï¼
        """
        p = self._get_pyaudio_instance()
        if not p:
            logger.error("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã€‚")
            return

        try:
            self.microphone_stream = p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
                stream_callback=self._microphone_callback
            )
            logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ãã¾ã—ãŸã€‚éŒ²éŸ³é–‹å§‹ï¼")

            while self.microphone_stream.is_active() and self._is_running:
                time.sleep(0.1)

        except Exception as e:
            logger.error(f"ğŸ˜± ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚ªãƒ¼ãƒ—ãƒ³ã¾ãŸã¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        finally:
            if self.microphone_stream:
                self.microphone_stream.stop_stream()
                self.microphone_stream.close()
                self.microphone_stream = None
                logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ãƒ»ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸã€‚")
            # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®çµ‚äº†ã¯ __del__ ã§è¡Œã†
            # p.terminate()

    def _microphone_callback(self, in_data, frame_count, time_info, status):
        """ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        # ã“ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã®ã§ã€éåŒæœŸã®putã§ã¯ãªãput_nowaitã‚’ä½¿ã†
        try:
            # process_audio_chunkã‚’ç›´æ¥å‘¼ã³å‡ºã™ã“ã¨ã§ãƒ”ãƒƒãƒè§£æã‚‚å®Ÿè¡Œ
            # ãŸã ã—ã€asyncé–¢æ•°ãªã®ã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã³å‡ºã™ã«ã¯å·¥å¤«ãŒå¿…è¦
            # ã“ã“ã§ã¯ event_loop ã‚’ä½¿ã£ã¦ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã™ã‚‹
            asyncio.run_coroutine_threadsafe(
                self.process_audio_chunk(in_data),
                self.main_loop
            )
        except Exception as e:
            logger.error(f"ãƒã‚¤ã‚¯ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã®ã‚­ãƒ¥ãƒ¼è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        return (in_data, pyaudio.paContinue)


    async def start_transcription_and_evaluation(self):
        """
        WebSocketã‹ã‚‰ã®éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ã‘ä»˜ã‘ã‚‹ãŸã‚ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ğŸ–¥ï¸ ã™ã§ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
            return

        logger.info("ğŸš€ WebSocketã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._stop_event.clear()
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ ---
        self.full_transcript = ""
        self.pitch_values = []
        self._pitch_buffer = b"" # ãƒ”ãƒƒãƒè§£æãƒãƒƒãƒ•ã‚¡ã‚‚ãƒªã‚»ãƒƒãƒˆ
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        # --- ã“ã“ã¾ã§ ---

        self._processing_task = asyncio.create_task(self._process_speech_stream())
        logger.info("ğŸ”¥ ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")

    async def start_realtime_transcription_from_mic(self):
        """
        ã€æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã€‘ãƒã‚¤ã‚¯ã‹ã‚‰ç›´æ¥éŸ³å£°ã‚’å–å¾—ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ğŸ™ï¸ ã™ã§ã«ãƒã‚¤ã‚¯ã‹ã‚‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
            return
        
        logger.info("ğŸš€ ãƒã‚¤ã‚¯ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._stop_event.clear()
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ ---
        self.full_transcript = ""
        self.pitch_values = []
        self._pitch_buffer = b"" # ãƒ”ãƒƒãƒè§£æãƒãƒƒãƒ•ã‚¡ã‚‚ãƒªã‚»ãƒƒãƒˆ
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        # --- ã“ã“ã¾ã§ ---

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚’å–å¾—
        self.main_loop = asyncio.get_running_loop()

        # ãƒã‚¤ã‚¯å…¥åŠ›ç”¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        self._microphone_task = threading.Thread(target=self._microphone_worker, daemon=True)
        self._microphone_task.start()
        
        # Speech-to-Textã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self._processing_task = asyncio.create_task(self._process_speech_stream())
        logger.info("ğŸ”¥ ãƒã‚¤ã‚¯éŸ³å£°ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")


    async def stop_transcription_and_evaluation(self):
        """
        æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã—ã€æœ€çµ‚è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆï¼
        """
        if not self._is_running:
            logger.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã™ã§ã«åœæ­¢ã—ã¦ã„ã¾ã™ã€‚")
            return
        
        logger.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³åœæ­¢ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...")

        # 1. ã¾ãšã¯æ–°ã—ã„éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘ä»˜ã‘ãªã„ã‚ˆã†ã«ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        self._is_running = False
        self._stop_event.set()

        # 2. éŸ³å£°ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã—ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«çµ‚äº†ã‚’é€šçŸ¥ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
        while not self._audio_queue.empty():
            self._audio_queue.get_nowait()
        await self._audio_queue.put(b"") #ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«çµ‚äº†ã•ã›ã‚‹

        # 3. ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        if self._processing_task and not self._processing_task.done():
            logger.info("ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™...")
            self._processing_task.cancel()
            try:
                await self._processing_task
            except asyncio.CancelledError:
                logger.info("ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¿ã‚¹ã‚¯ãŒæ­£å¸¸ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")

        # 4. ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ï¼ˆã“ã‚Œã¯_process_speech_streamã®finallyã§ã‚‚å‘¼ã°ã‚Œã‚‹ã‘ã©å¿µã®ãŸã‚ï¼‰
        await self._stop_workers()

        # 5. æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå‹•ã„ã¦ã„ãŸã‚‰åœæ­¢
        if self._microphone_task and self._microphone_task.is_alive():
            logger.info("æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã—ã¾ã™ã€‚")
            self._microphone_task.join()
            self._microphone_task = None

        logger.info("â³ å…¨ã¦ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚æœ€çµ‚è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™...")
        await self._send_to_client("evaluation_started", {})

        try:
            # 6. æœ€çµ‚è©•ä¾¡ã®å®Ÿè¡Œ
            final_evaluation = await self._run_final_evaluation()
            
            # 7. æœ€çµ‚è©•ä¾¡ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
            logger.info("ğŸ‘‘ æœ€çµ‚è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            # logger.debug(f"æœ€çµ‚è©•ä¾¡ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰: {final_evaluation}")
            await self._send_to_client("final_evaluation", {"evaluation": final_evaluation})
            
            # Geminiã‹ã‚‰ã®æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚‚é€ä¿¡
            if self.gemini_enabled and isinstance(final_evaluation, dict):
                 # `final_evaluation` ãŒè¾æ›¸ã§ã‚ã‚Šã€æœŸå¾…ã™ã‚‹ã‚­ãƒ¼ã‚’æŒã¤ã‹ç¢ºèª
                if "raw_evaluation" in final_evaluation and "score" in final_evaluation:
                    await self._send_to_client("gemini_feedback", final_evaluation)
                else:
                    # äº’æ›æ€§ã®ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    await self._send_to_client("gemini_feedback", {
                        "raw_evaluation": str(final_evaluation),
                        "score": 50 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
                    })

        except Exception as e:
            logger.error(f"ğŸ˜± æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            await self._send_to_client("error", {"message": "æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})
        
        logger.info("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸã€‚")


    async def _run_final_evaluation(self) -> dict | str:
        """
        ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†å¾Œã«ã€åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦Geminiã«æœ€çµ‚è©•ä¾¡ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã‚ˆï¼
        """
        logger.info("ğŸ§  Geminiã«ã‚ˆã‚‹æœ€çµ‚è©•ä¾¡ã‚’æº–å‚™ä¸­...")
        
        # åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒªãƒ¼
        self.last_pitch_analysis_summary = self._summarize_pitch_data()

        # Geminiã«æ¸¡ã™ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        evaluation_context = {
            "question": self.current_interview_question,
            "full_transcript": self.full_transcript,
            "pitch_analysis": self.last_pitch_analysis_summary,
            "emotion_analysis": self.last_emotion_analysis_summary
        }
        
        if self.gemini_enabled:
            try:
                # gemini_service ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™
                response_data = await gemini_service.generate_structured_feedback(evaluation_context)
                logger.info("ğŸ’ Geminiã‹ã‚‰è©•ä¾¡ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
                # response_data ã¯æ—¢ã«è¾æ›¸ã®ã¯ãš
                return response_data
            except Exception as e:
                logger.error(f"ğŸ˜± Geminiã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                return f"Geminiè©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        else:
            logger.warning("ğŸ˜¢ GeminiãŒç„¡åŠ¹ãªãŸã‚ã€æœ€çµ‚è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return "Geminiè©•ä¾¡ã¯ç¾åœ¨ç„¡åŠ¹ã§ã™ã€‚"


    def _summarize_pitch_data(self):
        """ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã™ã‚‹ã‚ˆ"""
        if not self.pitch_values:
            logger.info("ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ãŒåé›†ã•ã‚Œãªã‹ã£ãŸã®ã§ã€ãƒ”ãƒƒãƒã®è¦ç´„ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return {}

        # npã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        try:
            import numpy as np
        except ImportError:
            logger.warning("numpyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ”ãƒƒãƒã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
            return {}

        try:
            pitches = np.array(self.pitch_values)
            average_pitch = np.mean(pitches)
            pitch_variation = np.std(pitches)
            
            summary = {
                "average_pitch": f"{average_pitch:.2f}",
                "pitch_variation": f"{pitch_variation:.2f}",
            }
            return summary
        except Exception as e:
            logger.error(f"ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {}


    def __del__(self):
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒç ´æ£„ã•ã‚Œã‚‹ã¨ãã«PyAudioã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.pyaudio_instance:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£æ”¾ã—ã¾ã™ã€‚")
            self.pyaudio_instance.terminate()
            self.pyaudio_instance = None