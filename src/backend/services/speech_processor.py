# ã“ã“ã« Google Cloud Speech-to-Text ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹æ„Ÿã˜ã§ï¼
from google.cloud import speech_v1p1beta1 as speech # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ã†ã‚ˆï¼
from google.api_core import exceptions
import asyncio
import pyaudio
import logging # logging ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os # ç’°å¢ƒå¤‰æ•°ã®ãŸã‚ã«è¿½åŠ 
import time
import threading
from google.cloud import pubsub_v1 # â—€ï¸ Pub/Subãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
import json
import uuid # â—€ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆã®ãŸã‚ã«è¿½åŠ ï¼
from fastapi import WebSocket
from starlette.websockets import WebSocketDisconnect
from datetime import datetime

# --- Pythonã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œç´¢ãƒ‘ã‚¹ã«srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ  ---
import sys
# speech_processor.py ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (src/backend/services)
_CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ (src/backend/services -> src/backend -> src)
_SRC_DIR = os.path.abspath(os.path.join(_CURRENT_FILE_DIR, '..', '..'))
if _SRC_DIR not in sys.path:
    sys.path.insert(0, _SRC_DIR)
# --- ã“ã“ã¾ã§ ---

# --- ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from backend.services import gemini_service # gemini_serviceãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.workers.pitch_worker import PitchWorker
from backend.services import dialogflow_service # â—€ï¸ sentiment_worker ã®ä»£ã‚ã‚Šã« dialogflow_service ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.services.gemini_service import GeminiService
# æ–°ã—ãä½œã£ãŸå…±é€šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.shared_config import RATE, CHUNK, CHANNELS, FORMAT, SAMPLE_WIDTH

# logging ã®åŸºæœ¬è¨­å®š (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ï¼‘å›ã ã‘å®Ÿè¡Œ)
# SpeechProcessor ã‚¯ãƒ©ã‚¹ã®å¤–ã§è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ã‚ˆã‚“ï¼
logging.basicConfig(
    level=logging.INFO,  # é–‹ç™ºä¸­ã¯INFOãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã‚’è¡¨ç¤º
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
# ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = logging.getLogger(__name__)

# --- Pub/Subé–¢é€£ã®å®šæ•° ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹ã®ãŒã‚¤ã‚±ã¦ã‚‹ã‘ã©ã€ã¾ãšã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã§ã€‚å¾Œã§ç›´ã™ï¼
# TODO: GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã¨ãƒˆãƒ”ãƒƒã‚¯åã‚’å…±é€šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ã™ã‚‹
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID", "your-gcp-project-id")
TRANSCRIPTION_TOPIC = "ep-x-transcriptions"

# --- SpeechProcessorã‚¯ãƒ©ã‚¹ã§Geminié–¢é€£ã®ã‚³ãƒ¼ãƒ‰ã‚’ç®¡ç†ã™ã‚‹ã®ã§ã€ã“ã“ã®é‡è¤‡ã¯å‰Šé™¤ï¼ ---

class SpeechProcessor:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã®ã‚¯ãƒ©ã‚¹ã ã‚ˆã‚“ï¼
    æ–‡å­—èµ·ã“ã—ã€éŸ³ç¨‹è§£æã€æ„Ÿæƒ…åˆ†æã€Geminiè©•ä¾¡ã‚’ã¾ã¨ã‚ã¦ã‚„ã‚‹ãï¼
    """

    def __init__(self, websocket: WebSocket, send_to_client: callable):
        self.websocket = websocket
        self.send_to_client = send_to_client
        self.session_id = str(uuid.uuid4())
        self.gemini_service = GeminiService() # GeminiServiceã‚’åˆæœŸåŒ–
        self.speech_client = speech.SpeechAsyncClient()
        self._audio_queue = asyncio.Queue()
        self._is_running = False
        self._processing_task = None # ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ä¿æŒã™ã‚‹
        self._microphone_task = None # æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä¿æŒã™ã‚‹
        self._stop_event = asyncio.Event()
        self.main_loop = asyncio.get_event_loop()
        self.pyaudio_instance = None
        self.microphone_stream = None

        # --- Pub/Sub Publisherã®åˆæœŸåŒ– ---
        try:
            self.publisher = pubsub_v1.PublisherClient()
            self.topic_path = self.publisher.topic_path(GCP_PROJECT_ID, TRANSCRIPTION_TOPIC)
            logger.info(f"âœ… Pub/Sub Publisherã®åˆæœŸåŒ–å®Œäº†ï¼ãƒˆãƒ”ãƒƒã‚¯: {self.topic_path}")
        except Exception as e:
            logger.exception("ğŸ˜± Pub/Sub Publisher ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.publisher = None
            self.topic_path = None
        # --- ã“ã“ã¾ã§Pub/SubåˆæœŸåŒ– ---

        # PitchWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            self.pitch_worker = PitchWorker(
                sample_rate=RATE,
                channels=CHANNELS,
                sample_width=SAMPLE_WIDTH,
            )
            logger.info("ğŸµ PitchWorker ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± PitchWorker ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.pitch_worker = None

        logger.info("âœ¨ SpeechProcessor åˆæœŸåŒ–å®Œäº†ï¼âœ¨")
        logger.info(f"PyAudioè¨­å®š: FORMAT={FORMAT}, CHANNELS={CHANNELS}, RATE={RATE}, CHUNK={CHUNK}, SAMPLE_WIDTH={SAMPLE_WIDTH}")

        # --- Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®åˆæœŸåŒ– ---
        # __init__ã§ç”Ÿæˆã—ãŸGeminiServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹
        self.gemini_enabled = self.gemini_service.gemini_model_instance is not None
        if self.gemini_enabled:
            logger.info("ğŸ‘‘ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸã€‚")
        else:
            logger.warning("ğŸ˜¢ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã¯ç„¡åŠ¹ã§ã™ã€‚è¨­å®šã¾ãŸã¯èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹å¤‰æ•°ã‚’åˆæœŸåŒ– ---
        self.current_interview_question = "è‡ªå·±PRã‚’ã—ã¦ãã ã•ã„ã€‚" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•
        self.full_transcript = "" # æ–‡å­—èµ·ã“ã—å…¨æ–‡ã‚’ä¿æŒ
        self.pitch_values = []    # ãƒ”ãƒƒãƒã®æ¸¬å®šå€¤ã‚’ä¿æŒ
        self.last_pitch_analysis_summary = {} # ãƒ”ãƒƒãƒè§£æã®é›†è¨ˆçµæœ
        self.last_emotion_analysis_summary = {} # æ„Ÿæƒ…åˆ†æã®é›†è¨ˆçµæœ
        
        # --- ãƒ”ãƒƒãƒè§£æç”¨ã®ãƒãƒƒãƒ•ã‚¡ã¨è¨­å®šã‚’è¿½åŠ  ---
        self._pitch_buffer = b""
        self._required_pitch_bytes = 0
        if self.pitch_worker:
            # pitch_workerãŒå¿…è¦ã¨ã™ã‚‹æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°(max_lag)ã®2å€ã‚’ãƒã‚¤ãƒˆæ•°ã§è¨ˆç®—
            # 2å€ã«ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå®‰å®šã—ãŸè§£æãŒæœŸå¾…ã§ãã‚‹
            # ä¾‹: 16000Hz / 50Hz(min_freq) = 320ã‚µãƒ³ãƒ—ãƒ« -> 320 * 2(bytes) * 2 = 1280ãƒã‚¤ãƒˆ
            self._required_pitch_bytes = self.pitch_worker.max_lag * self.pitch_worker.sample_width * 2
            logger.info(f"ãƒ”ãƒƒãƒè§£æã«å¿…è¦ãªæœ€å°ãƒã‚¤ãƒˆæ•°: {self._required_pitch_bytes}")
        # --- ã“ã“ã¾ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å¤‰æ•° ---

    def _reset_session_data(self):
        """
        ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹å†…éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã€‚
        start_transcription_and_evaluation ãŒå‘¼ã°ã‚ŒãŸã¨ãã«å®Ÿè¡Œã™ã‚‹ã€‚
        """
        self.session_id = str(uuid.uuid4())
        self._audio_queue = asyncio.Queue()
        self._stop_event.clear()
        self.full_transcript = ""
        self.pitch_values = []
        self._pitch_buffer = b""
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        logger.info(f"æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ: {self.session_id}")

    async def process_audio_chunk(self, chunk: bytes):
        """
        WebSocketã‹ã‚‰å—ã‘å–ã£ãŸéŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚ˆã€‚
        ãƒ”ãƒƒãƒè§£æã€æ„Ÿæƒ…åˆ†æã€æ–‡å­—èµ·ã“ã—ã‚­ãƒ¥ãƒ¼ã¸ã®è¿½åŠ ã‚’è¡Œã†ã€‚
        """
        if not self._is_running:
            return

        # 1. ãƒ”ãƒƒãƒã‚’è§£æ
        if self.pitch_worker and self._required_pitch_bytes > 0:
            self._pitch_buffer += chunk

            # ãƒãƒƒãƒ•ã‚¡ãŒååˆ†ãªå¤§ãã•ã«ãªã£ãŸã‚‰è§£æ
            if len(self._pitch_buffer) >= self._required_pitch_bytes:
                pitch = self.pitch_worker.analyze_pitch(self._pitch_buffer)
                
                if pitch is not None:
                    # æœ€çµ‚è©•ä¾¡ç”¨ã«è“„ç©
                    self.pitch_values.append(pitch)
                    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡ï¼
                    timestamp = time.time()
                    await self._send_to_client(
                        "pitch_analysis",
                        {"pitch": pitch, "timestamp": timestamp}
                    )
                
                # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¹ãƒ©ã‚¤ãƒ‰ã•ã›ã‚‹ (å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤)
                # ä»Šå›ã¯è§£æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®åŠåˆ†ã‚’å‰Šé™¤ã—ã¦ã€æ¬¡ã®è§£æã¨ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã•ã›ã‚‹
                slide_bytes = self._required_pitch_bytes // 2
                self._pitch_buffer = self._pitch_buffer[slide_bytes:]

        # 2. Symbl.aiã¸ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ã¯ä¸è¦ã«ãªã£ãŸã®ã§å‰Šé™¤ï¼

        # 3. æ–‡å­—èµ·ã“ã—ç”¨ã®ã‚­ãƒ¥ãƒ¼ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if not self._stop_event.is_set():
            await self._audio_queue.put(chunk)

    async def _start_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã®èµ·å‹•å‡¦ç†ï¼ˆç¾åœ¨ã¯ç©ºï¼‰"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯èµ·å‹•ã—ãªã„
        # SentimentWorkerã‚‚ã„ãªããªã£ãŸã®ã§ã€ã“ã“ã¯ç©ºã£ã½ï¼
        pass

    async def _stop_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åœæ­¢å‡¦ç†ï¼ˆç¾åœ¨ã¯ç©ºï¼‰"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯åœæ­¢ã—ãªã„
        # SentimentWorkerã‚‚ã„ãªããªã£ãŸã®ã§ã€ã“ã“ã¯ç©ºã£ã½ï¼
        pass

    def _get_pyaudio_instance(self):
        """PyAudioã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã¾ãŸã¯ç”Ÿæˆã™ã‚‹ã‚ˆã€‚ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆã®æ™‚ã ã‘ã­ï¼"""
        if self.pyaudio_instance is None:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒãªã„ã®ã§ã€æ–°ã—ãä½œã‚‹ã‚ˆï¼")
            try:
                self.pyaudio_instance = pyaudio.PyAudio()
                logger.info("ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆç”¨ã«PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ–°ã—ãä½œã£ãŸã‚ˆï¼")
            except Exception:
                # ã“ã“ã§ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚å‡ºåŠ›ã™ã‚‹
                logger.error("PyAudioã®åˆæœŸåŒ–ä¸­ã«ã‚¬ãƒãªã‚¨ãƒ©ãƒ¼ã§ã¡ã‚ƒã£ãŸâ€¦", exc_info=True)
                self.pyaudio_instance = None # å¤±æ•—ã—ãŸã‚‰Noneã«æˆ»ã™
        return self.pyaudio_instance

    async def _send_to_client(self, data_type, payload):
        """ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–æ™‚ã«æ¸¡ã•ã‚ŒãŸsend_to_clienté–¢æ•°çµŒç”±ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«JSONãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹"""
        if self.send_to_client:
            message = {"type": data_type, "payload": payload}
            await self.send_to_client(message)

    def _get_speech_client(self):
        # ... existing code ...
        pass

    def set_interview_question(self, question: str):
        """ç¾åœ¨ã®é¢æ¥ã®è³ªå•ã‚’è¨­å®šã™ã‚‹ã‚ˆã‚“ï¼"""
        self.current_interview_question = question
        logger.info(f"ğŸ¤ è¨­å®šã•ã‚ŒãŸé¢æ¥ã®è³ªå•: {question}")

    # --- Symbl.aiç”¨ã® _handle_emotion_data ã¯ä¸è¦ã«ãªã£ãŸã®ã§å®Œå…¨ã«å‰Šé™¤ï¼ ---

    async def _publish_to_pubsub(self, message_data: dict):
        """
        æ–‡å­—èµ·ã“ã—çµæœãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’Pub/Subã«éåŒæœŸã§é€ä¿¡ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if not self.publisher or not self.topic_path:
            logger.error("Pub/Sub PublisherãŒåˆæœŸåŒ–ã•ã‚Œã¦ãªã„ãŸã‚ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã§ãã¾ã›ã‚“ã€‚")
            return

        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã®ãƒã‚¤ãƒˆæ–‡å­—åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            data = json.dumps(message_data, ensure_ascii=False).encode("utf-8")
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ‘ãƒ–ãƒªãƒƒã‚·ãƒ¥ï¼
            future = self.publisher.publish(self.topic_path, data)
            # é€ä¿¡çµæœã‚’å¾…ã¤ï¼ˆéåŒæœŸãªã®ã§ã€ã“ã“ã§ã¯å¾…ãŸãšã«ãƒ­ã‚°ã ã‘å‡ºã™ï¼‰
            future.add_done_callback(lambda f: logger.info(f"ğŸ“¤ Pub/Subã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å®Œäº†: {f.result()}"))
            # await future # ã“ã“ã§å¾…ã¤ã¨ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã—ã¡ã‚ƒã†ã®ã§æ³¨æ„ï¼
        except exceptions.GoogleAPICallError as e:
            logger.error(f"ğŸ˜± Pub/Subã¸ã®é€ä¿¡ä¸­ã«APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        except Exception as e:
            logger.exception("ğŸ˜± Pub/Subã¸ã®é€ä¿¡ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

    async def _process_speech_stream(self):
        """
        éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†ã—ã¦ã€æ–‡å­—èµ·ã“ã—ã¨å„ç¨®åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã ã‚ˆã‚“ã€‚
        """
        # --- 1. éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ç”Ÿæˆ ---
        audio_stream_generator = self._audio_stream_generator()

        # --- 2. Google Cloud Speech-to-Text APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®š ---
        # ...ï¼ˆä¸­ç•¥ï¼‰...
        recognition_config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=RATE,
            language_code="ja-JP",
            enable_automatic_punctuation=True,
            profanity_filter=True, # ä¸é©åˆ‡ãªå˜èªã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=recognition_config,
            interim_results=True, # æš«å®šçš„ãªçµæœã‚‚å—ã‘å–ã‚‹
        )

        requests = self._create_streaming_requests(audio_stream_generator)

        try:
            logger.info("ğŸš€ Google Speech-to-Text APIã¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
            # recognizeãƒ¡ã‚½ãƒƒãƒ‰ã¯éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’è¿”ã™ï¼
            # ä¿®æ­£ç‚¹: streaming_recognizeã¯ã‚³ãƒ«ãƒ¼ãƒãƒ³ãªã®ã§awaitã™ã‚‹
            stream = await self.speech_client.streaming_recognize(
                requests=requests
            )

            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’éåŒæœŸã§å‡¦ç†
            async for response in stream:
                if not self._is_running:
                    break
                
                if response.results:
                    result = response.results[0]
                    if result.alternatives:
                        transcript_chunk = result.alternatives[0].transcript

                        # ç¢ºå®šã—ãŸæ–‡å­—èµ·ã“ã—ã¯å…¨æ–‡ã«çµåˆ
                        if result.is_final:
                            self.full_transcript += transcript_chunk + " "
                            logger.info(f"âœ… æœ€çµ‚çš„ãªæ–‡å­—èµ·ã“ã—çµæœã®æ–­ç‰‡: '{transcript_chunk}' (çµåˆå¾Œã®å…¨æ–‡: '{self.full_transcript[:50]}...')")

                            # æ„Ÿæƒ…åˆ†æã¯ç¢ºå®šã—ãŸæ–­ç‰‡ã”ã¨ã«è¡Œã†
                            if len(transcript_chunk.strip()) > 1: # 1æ–‡å­—ä»¥ä¸Šãªã‚‰
                                try:
                                    logger.info(f"ğŸ¤– Dialogflowã«æ„Ÿæƒ…åˆ†æã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: '{transcript_chunk}'")
                                    sentiment_result = await dialogflow_service.analyze_sentiment(
                                        session_id=self.session_id, text=transcript_chunk
                                    )
                                    # WebSocketã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æ„Ÿæƒ…åˆ†æçµæœã‚’é€ä¿¡
                                    if sentiment_result:
                                        await self._send_to_client("sentiment_update", {
                                            "sentiment": sentiment_result,
                                            "timestamp": datetime.now().isoformat()
                                        })
                                except Exception as e:
                                    logger.error(f"æ„Ÿæƒ…åˆ†æã®å‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™: {e}")

                        # interimã‚‚finalã‚‚ã€å¸¸ã«æ›´æ–°ã•ã‚ŒãŸå…¨æ–‡ã‚’ãƒ•ãƒ­ãƒ³ãƒˆã«é€ã‚‹ï¼
                        # ã“ã‚Œã§ãƒ•ãƒ­ãƒ³ãƒˆã¯è¡¨ç¤ºã‚’æ›´æ–°ã™ã‚‹ã ã‘ã§ã‚ˆããªã‚‹
                        current_display_transcript = self.full_transcript + transcript_chunk if not result.is_final else self.full_transcript

                        realtime_data = {
                            "transcript": current_display_transcript,
                            "is_final": result.is_final
                        }
                        await self._send_to_client("transcript_update", realtime_data)

        except WebSocketDisconnect:
            logger.warning("ğŸ¤ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®é€”ä¸­ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ‡æ–­ã—ãŸã£ã½ï¼å‡¦ç†ã‚’çµ‚äº†ã™ã‚‹ã­ã€œğŸ‘‹")
        except exceptions.Cancelled as e:
            logger.warning("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã¯æ­£å¸¸ãªåœæ­¢å‡¦ç†ã®ä¸€éƒ¨ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        except exceptions.OutOfRange as e:
            logger.error(f"ğŸ˜± éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®çµ‚ç«¯ã«é”ã—ã¾ã—ãŸ: {e}")
        except exceptions.GoogleAPICallError as e:
            logger.error(f"ğŸ˜± Google Speech-to-Text APIã§ã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            logger.exception(f"ğŸ˜± _process_speech_streamã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        finally:
            logger.info("ğŸ‘‹ _process_speech_stream ãƒ«ãƒ¼ãƒ—ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚")
            self._stop_event.set()

    async def _create_streaming_requests(self, audio_generator):
        """
        Google Speech-to-Text APIã«é€ä¿¡ã™ã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã ã‚ˆã‚“ã€‚
        æœ€åˆã«è¨­å®šæƒ…å ±ã‚’é€ã£ã¦ã€ãã®ã‚ã¨ã¯ã²ãŸã™ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹ï¼
        """
        # æœ€åˆã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šã‚’é€ä¿¡
        recognition_config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=RATE,
            language_code="ja-JP",
            enable_automatic_punctuation=True,
            profanity_filter=True,
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=recognition_config,
            interim_results=True,
        )
        yield speech.StreamingRecognizeRequest(streaming_config=streaming_config)

        # ãã®å¾Œã¯éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’éåŒæœŸã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
        async for chunk in audio_generator:
            if not chunk:
                break
            yield speech.StreamingRecognizeRequest(audio_content=chunk)

    async def _audio_stream_generator(self):
        """ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å‡ºã—ã¦ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¨ã—ã¦è¿”ã™éåŒæœŸé–¢æ•°"""
        while self._is_running and not self._stop_event.is_set():
            try:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                chunk = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                yield chunk
            except asyncio.TimeoutError:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯ã‚¨ãƒ©ãƒ¼ã˜ã‚ƒãªã„ã€‚ãƒ‡ãƒ¼ã‚¿ãŒæ¥ã¦ãªã„ã ã‘ã ã‹ã‚‰ãƒ«ãƒ¼ãƒ—ã‚’ç¶šã‘ã‚‹
                continue
            except asyncio.CancelledError:
                logger.info("ğŸ¤ _audio_stream_generatorãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
                break
        
        logger.info("ğŸ¤ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãŒçµ‚äº†ã—ã¾ã™ã€‚")

    def _microphone_worker(self):
        """
        PyAudioã‚’ä½¿ã£ã¦ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã—ã€éåŒæœŸã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•°ã€‚
        ã“ã‚Œã¯æ‰‹å‹•ãƒ†ã‚¹ãƒˆ (`manual_test_speech_processor.py`) ã®ãŸã‚ã®ã‚‚ã®ã ã‚ˆã‚“ï¼
        """
        p = self._get_pyaudio_instance()
        if not p:
            logger.error("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã€‚")
            return

        try:
            self.microphone_stream = p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
                stream_callback=self._microphone_callback
            )
            logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ãã¾ã—ãŸã€‚éŒ²éŸ³é–‹å§‹ï¼")

            while self.microphone_stream.is_active() and self._is_running:
                time.sleep(0.1)

        except Exception as e:
            logger.error(f"ğŸ˜± ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚ªãƒ¼ãƒ—ãƒ³ã¾ãŸã¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        finally:
            if self.microphone_stream:
                self.microphone_stream.stop_stream()
                self.microphone_stream.close()
                self.microphone_stream = None
                logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ãƒ»ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸã€‚")
            # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®çµ‚äº†ã¯ __del__ ã§è¡Œã†
            # p.terminate()

    def _microphone_callback(self, in_data, frame_count, time_info, status):
        """ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        # ã“ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã®ã§ã€éåŒæœŸã®putã§ã¯ãªãput_nowaitã‚’ä½¿ã†
        try:
            # process_audio_chunkã‚’ç›´æ¥å‘¼ã³å‡ºã™ã“ã¨ã§ãƒ”ãƒƒãƒè§£æã‚‚å®Ÿè¡Œ
            # ãŸã ã—ã€asyncé–¢æ•°ãªã®ã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã³å‡ºã™ã«ã¯å·¥å¤«ãŒå¿…è¦
            # ã“ã“ã§ã¯ event_loop ã‚’ä½¿ã£ã¦ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã™ã‚‹
            asyncio.run_coroutine_threadsafe(
                self.process_audio_chunk(in_data),
                self.main_loop
            )
        except Exception as e:
            logger.error(f"ãƒã‚¤ã‚¯ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã®ã‚­ãƒ¥ãƒ¼è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        return (in_data, pyaudio.paContinue)


    async def start_transcription_and_evaluation(self):
        """
        æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã™ã‚‹ãƒ¡ã‚¤ãƒ³ã®é–¢æ•°ã ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã™ã§ã«å®Ÿè¡Œä¸­ã§ã™ã€‚")
            return

        logger.info("ğŸš€ WebSocketã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._reset_session_data() # â—€ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆï¼
        
        # _process_speech_stream ã‚’éåŒæœŸã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œ
        self._processing_task = self.main_loop.create_task(self._process_speech_stream())
        
        # é–¢é€£ã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•
        await self._start_workers()

    async def start_realtime_transcription_from_mic(self):
        """
        ã€æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã€‘ãƒã‚¤ã‚¯ã‹ã‚‰ç›´æ¥éŸ³å£°ã‚’å–å¾—ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ğŸ™ï¸ ã™ã§ã«ãƒã‚¤ã‚¯ã‹ã‚‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
            return
        
        logger.info("ğŸš€ ãƒã‚¤ã‚¯ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._stop_event.clear()
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ ---
        self.full_transcript = ""
        self.pitch_values = []
        self._pitch_buffer = b"" # ãƒ”ãƒƒãƒè§£æãƒãƒƒãƒ•ã‚¡ã‚‚ãƒªã‚»ãƒƒãƒˆ
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        # --- ã“ã“ã¾ã§ ---

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚’å–å¾—
        self.main_loop = asyncio.get_running_loop()

        # ãƒã‚¤ã‚¯å…¥åŠ›ç”¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        self._microphone_task = threading.Thread(target=self._microphone_worker, daemon=True)
        self._microphone_task.start()
        
        # Speech-to-Textã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self._processing_task = asyncio.create_task(self._process_speech_stream())
        logger.info("ğŸ”¥ ãƒã‚¤ã‚¯éŸ³å£°ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")


    async def stop_transcription_and_evaluation(self):
        """
        æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã—ã€æœ€çµ‚è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆï¼
        """
        if not self._is_running:
            logger.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã™ã§ã«åœæ­¢ã—ã¦ã„ã¾ã™ã€‚")
            return
        
        logger.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³åœæ­¢ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...")

        # 1. ã¾ãšã¯æ–°ã—ã„éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘ä»˜ã‘ãªã„ã‚ˆã†ã«ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        self._is_running = False
        self._stop_event.set()

        # 2. éŸ³å£°ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã—ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«çµ‚äº†ã‚’é€šçŸ¥ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
        while not self._audio_queue.empty():
            self._audio_queue.get_nowait()
        await self._audio_queue.put(b"") #ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«çµ‚äº†ã•ã›ã‚‹

        # 3. ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        if self._processing_task and not self._processing_task.done():
            logger.info("ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™...")
            self._processing_task.cancel()
            try:
                await self._processing_task
            except asyncio.CancelledError:
                logger.info("ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¿ã‚¹ã‚¯ãŒæ­£å¸¸ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")

        # 4. ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ï¼ˆã“ã‚Œã¯_process_speech_streamã®finallyã§ã‚‚å‘¼ã°ã‚Œã‚‹ã‘ã©å¿µã®ãŸã‚ï¼‰
        await self._stop_workers()

        # 5. æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå‹•ã„ã¦ã„ãŸã‚‰åœæ­¢
        if self._microphone_task and self._microphone_task.is_alive():
            logger.info("æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã—ã¾ã™ã€‚")
            self._microphone_task.join()
            self._microphone_task = None

        logger.info("â³ å…¨ã¦ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚æœ€çµ‚è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™...")
        await self._send_to_client("evaluation_started", {})

        try:
            # 6. æœ€çµ‚è©•ä¾¡ã®å®Ÿè¡Œ
            final_evaluation_result = await self._run_final_evaluation()
            
            # 7. æœ€çµ‚è©•ä¾¡ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
            if final_evaluation_result and "error" not in final_evaluation_result:
                logger.info("ğŸ‘‘ æœ€çµ‚è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡ã—ã¾ã™ã€‚")
                await self._send_to_client("final_evaluation", final_evaluation_result)
            else:
                logger.error("æœ€çµ‚è©•ä¾¡ã«å¤±æ•—ã—ãŸã‹ã€ã‚¨ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚")
                error_message = final_evaluation_result.get("error", "æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆä¸­ã«ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚") if isinstance(final_evaluation_result, dict) else "æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆä¸­ã«ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
                await self._send_to_client("error", {"message": error_message})

        except Exception as e:
            logger.error(f"ğŸ˜± æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆãƒ»é€ä¿¡ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            await self._send_to_client("error", {"message": "æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆä¸­ã«ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})
        
        logger.info("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸã€‚")


    async def _run_final_evaluation(self) -> dict:
        """
        ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†å¾Œã«ã€åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦Geminiã«æœ€çµ‚è©•ä¾¡ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã‚ˆï¼
        """
        logger.info("ğŸ§  Geminiã«ã‚ˆã‚‹æœ€çµ‚è©•ä¾¡ã‚’æº–å‚™ä¸­...")

        if not self.gemini_enabled:
            logger.warning("Geminiè©•ä¾¡ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return {"error": "Gemini evaluation is disabled."}

        # 1. ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
        pitch_summary = self._summarize_pitch_data()
        
        # TODO: æ„Ÿæƒ…åˆ†æãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã™ã‚‹
        logger.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®æ„Ÿæƒ…åˆ†æãƒ‡ãƒ¼ã‚¿ã¯ç¾åœ¨é›†è¨ˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æœ€çµ‚è©•ä¾¡ã§ã¯ãƒ€ãƒŸãƒ¼å€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        emotion_summary = {
            "dominant_emotion": "åˆ†æä¸­",
            "emotion_score": "N/A"
        }

        # 2. Geminiã«æ¸¡ã™ãŸã‚ã®è©•ä¾¡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        evaluation_context = {
            "interview_question": self.current_interview_question,
            "transcript": self.full_transcript,
            "average_pitch": pitch_summary.get("average_pitch", "N/A"),
            "pitch_variation": pitch_summary.get("pitch_variation", "N/A"),
            "dominant_emotion": emotion_summary.get("dominant_emotion", "N/A"),
            "emotion_score": emotion_summary.get("emotion_score", "N/A"),
        }
        
        logger.info("Geminiã«æ¸¡ã™è©•ä¾¡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
        
        # 3. Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚’å‘¼ã³å‡ºã—
        try:
            gemini_eval = await self.gemini_service.generate_structured_feedback(
                evaluation_context=evaluation_context
            )
        except Exception as e:
            logger.error(f"Geminiã‚µãƒ¼ãƒ“ã‚¹å‘¼ã³å‡ºã—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
            return {"error": "An unexpected error occurred while calling the Gemini service."}
        
        # 4. çµæœã‚’å‡¦ç†ã—ã¦è¿”ã™
        if gemini_eval and "error" not in gemini_eval:
            logger.info("ğŸ’ Geminiã‹ã‚‰æ§‹é€ åŒ–ã•ã‚ŒãŸè©•ä¾¡ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
            return gemini_eval
        else:
            error_msg = gemini_eval.get('error') if gemini_eval else 'No response from Gemini'
            logger.error(f"â›‘ï¸ Geminiã‹ã‚‰ã®è©•ä¾¡å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_msg}")
            return {"error": f"Failed to get evaluation from Gemini: {error_msg}"}


    def _summarize_pitch_data(self):
        """ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã™ã‚‹ã‚ˆ"""
        if not self.pitch_values:
            logger.info("ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ãŒåé›†ã•ã‚Œãªã‹ã£ãŸã®ã§ã€ãƒ”ãƒƒãƒã®è¦ç´„ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return {}

        # npã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        try:
            import numpy as np
        except ImportError:
            logger.warning("numpyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ”ãƒƒãƒã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
            return {}

        try:
            pitches = np.array(self.pitch_values)
            average_pitch = np.mean(pitches)
            pitch_variation = np.std(pitches)
            
            summary = {
                "average_pitch": f"{average_pitch:.2f}",
                "pitch_variation": f"{pitch_variation:.2f}",
            }
            return summary
        except Exception as e:
            logger.error(f"ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {}


    def __del__(self):
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒç ´æ£„ã•ã‚Œã‚‹ã¨ãã«PyAudioã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.pyaudio_instance:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£æ”¾ã—ã¾ã™ã€‚")
            self.pyaudio_instance.terminate()
            self.pyaudio_instance = None