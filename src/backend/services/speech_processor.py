# ã“ã“ã« Google Cloud Speech-to-Text ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹æ„Ÿã˜ã§ï¼
from google.cloud import speech_v1p1beta1 as speech # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ã†ã‚ˆï¼
from google.api_core import exceptions
import asyncio
import pyaudio
import logging # logging ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os # ç’°å¢ƒå¤‰æ•°ã®ãŸã‚ã«è¿½åŠ 
import time
import threading

# --- Pythonã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œç´¢ãƒ‘ã‚¹ã«srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ  ---
import sys
# speech_processor.py ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (src/backend/services)
_CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ (src/backend/services -> src/backend -> src)
_SRC_DIR = os.path.abspath(os.path.join(_CURRENT_FILE_DIR, '..', '..'))
if _SRC_DIR not in sys.path:
    sys.path.insert(0, _SRC_DIR)
# --- ã“ã“ã¾ã§ ---

# --- ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from backend.services import gemini_service # gemini_serviceãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.workers.pitch_worker import PitchWorker
from backend.workers.sentiment_worker import SentimentWorker
# æ–°ã—ãä½œã£ãŸå…±é€šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼
from backend.shared_config import RATE, CHUNK, CHANNELS, FORMAT, SAMPLE_WIDTH

# logging ã®åŸºæœ¬è¨­å®š (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ï¼‘å›ã ã‘å®Ÿè¡Œ)
# SpeechProcessor ã‚¯ãƒ©ã‚¹ã®å¤–ã§è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ã‚ˆã‚“ï¼
logging.basicConfig(
    level=logging.INFO,  # é–‹ç™ºä¸­ã¯INFOãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã‚’è¡¨ç¤º
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
# ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = logging.getLogger(__name__)

# --- SpeechProcessorã‚¯ãƒ©ã‚¹ã§Geminié–¢é€£ã®ã‚³ãƒ¼ãƒ‰ã‚’ç®¡ç†ã™ã‚‹ã®ã§ã€ã“ã“ã®é‡è¤‡ã¯å‰Šé™¤ï¼ ---

class SpeechProcessor:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã®ã‚¯ãƒ©ã‚¹ã ã‚ˆã‚“ï¼
    æ–‡å­—èµ·ã“ã—ã€éŸ³ç¨‹è§£æã€æ„Ÿæƒ…åˆ†æã€Geminiè©•ä¾¡ã‚’ã¾ã¨ã‚ã¦ã‚„ã‚‹ãï¼
    """

    def __init__(self):
        self.speech_client = speech.SpeechAsyncClient()
        self._audio_queue = asyncio.Queue()
        self._is_running = False
        self._processing_task = None # ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ä¿æŒã™ã‚‹
        self._microphone_task = None # æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä¿æŒã™ã‚‹
        self._stop_event = asyncio.Event()
        self.main_loop = asyncio.get_event_loop()
        self.pyaudio_instance = None
        self.microphone_stream = None
        self.send_to_client_callback = None # é€ä¿¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

        # PitchWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            self.pitch_worker = PitchWorker(
                sample_rate=RATE,
                channels=CHANNELS,
                sample_width=SAMPLE_WIDTH,
            )
            logger.info("ğŸµ PitchWorker ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± PitchWorker ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.pitch_worker = None

        # SentimentWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            # Google Cloud Natural Language API ã‚’ä½¿ã†ã®ã§ã€APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ã§è¨­å®šã•ã‚Œã¦ã‚‹å‰æã ã‚ˆã‚“ï¼
            self.sentiment_worker = SentimentWorker(
                on_emotion_callback=self._handle_emotion_data,
                language_code="ja" # Google Cloud NL API ã¯ "ja" ã‚’ä½¿ã†ã‚ˆï¼
            )
            logger.info("ğŸ˜Š SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e: # SentimentWorkerå†…ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã‚‚ã‚­ãƒ£ãƒƒãƒã§ãã‚‹ã‚ˆã†ã«æ±ç”¨çš„ãªExceptionã«
            logger.exception("ğŸ˜± SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.sentiment_worker = None

        logger.info("âœ¨ SpeechProcessor åˆæœŸåŒ–å®Œäº†ï¼âœ¨")
        logger.info(f"PyAudioè¨­å®š: FORMAT={FORMAT}, CHANNELS={CHANNELS}, RATE={RATE}, CHUNK={CHUNK}, SAMPLE_WIDTH={SAMPLE_WIDTH}")

        # --- Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®åˆæœŸåŒ– ---
        # gemini_service ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«åˆæœŸåŒ–ãŒèµ°ã‚‹ã‹ã‚‰ã€ã“ã“ã§ã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã ã‘ï¼
        self.gemini_enabled = gemini_service.gemini_model_instance is not None
        if self.gemini_enabled:
            logger.info("ğŸ‘‘ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸã€‚")
        else:
            logger.warning("ğŸ˜¢ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã¯ç„¡åŠ¹ã§ã™ã€‚è¨­å®šã¾ãŸã¯èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹å¤‰æ•°ã‚’åˆæœŸåŒ– ---
        self.current_interview_question = "è‡ªå·±PRã‚’ã—ã¦ãã ã•ã„ã€‚" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•
        self.full_transcript = "" # æ–‡å­—èµ·ã“ã—å…¨æ–‡ã‚’ä¿æŒ
        self.pitch_values = []    # ãƒ”ãƒƒãƒã®æ¸¬å®šå€¤ã‚’ä¿æŒ
        self.last_pitch_analysis_summary = {} # ãƒ”ãƒƒãƒè§£æã®é›†è¨ˆçµæœ
        self.last_emotion_analysis_summary = {} # æ„Ÿæƒ…åˆ†æã®é›†è¨ˆçµæœ
        # --- ã“ã“ã¾ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å¤‰æ•° ---

    async def process_audio_chunk(self, chunk: bytes):
        """
        WebSocketã‹ã‚‰å—ã‘å–ã£ãŸéŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚ˆã€‚
        ãƒ”ãƒƒãƒè§£æã¨ã€æ–‡å­—èµ·ã“ã—ã‚­ãƒ¥ãƒ¼ã¸ã®è¿½åŠ ã‚’è¡Œã†ã€‚
        """
        if not self._is_running:
            return

        # 1. ãƒ”ãƒƒãƒã‚’è§£æ
        if self.pitch_worker:
            pitch = self.pitch_worker.analyze_pitch(chunk)
            if pitch is not None:
                self.pitch_values.append(pitch)
                # logger.debug(f"ğŸ¤ æ¤œå‡ºã•ã‚ŒãŸãƒ”ãƒƒãƒ: {pitch:.2f} Hz") # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¾¿åˆ©

        # 2. æ–‡å­—èµ·ã“ã—ç”¨ã®ã‚­ãƒ¥ãƒ¼ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if not self._stop_event.is_set():
            await self._audio_queue.put(chunk)

    async def _start_workers(self):
        """æ„Ÿæƒ…åˆ†æãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•ã™ã‚‹ã‚ˆã‚“ï¼"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯èµ·å‹•ã—ãªã„
        if self.sentiment_worker:
            # startãŒéåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§awaitã™ã‚‹
            await self.sentiment_worker.start()

    async def _stop_workers(self):
        """æ„Ÿæƒ…åˆ†æãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ã™ã‚‹ã‚ˆã‚“ï¼"""
        # PitchWorkerã¯éƒ½åº¦å‘¼ã³å‡ºã™ã®ã§ã€ã“ã“ã§ã¯åœæ­¢ã—ãªã„
        if self.sentiment_worker:
            # stopãŒéåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§awaitã™ã‚‹
            await self.sentiment_worker.stop()

    def _get_pyaudio_instance(self):
        """PyAudioã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã¾ãŸã¯ç”Ÿæˆã™ã‚‹ã‚ˆã€‚ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆã®æ™‚ã ã‘ã­ï¼"""
        if self.pyaudio_instance is None:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒãªã„ã®ã§ã€æ–°ã—ãä½œã‚‹ã‚ˆï¼")
            try:
                self.pyaudio_instance = pyaudio.PyAudio()
                logger.info("ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆç”¨ã«PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ–°ã—ãä½œã£ãŸã‚ˆï¼")
            except Exception:
                # ã“ã“ã§ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚å‡ºåŠ›ã™ã‚‹
                logger.error("PyAudioã®åˆæœŸåŒ–ä¸­ã«ã‚¬ãƒãªã‚¨ãƒ©ãƒ¼ã§ã¡ã‚ƒã£ãŸâ€¦", exc_info=True)
                self.pyaudio_instance = None # å¤±æ•—ã—ãŸã‚‰Noneã«æˆ»ã™
        return self.pyaudio_instance

    def set_send_to_client_callback(self, callback):
        """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹ãŸã‚ã®éåŒæœŸã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’ã‚»ãƒƒãƒˆã™ã‚‹ã‚ˆ"""
        self.send_to_client_callback = callback

    async def _send_to_client(self, data_type, payload):
        """ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯çµŒç”±ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«JSONãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹"""
        if self.send_to_client_callback:
            message = {"type": data_type, "payload": payload}
            await self.send_to_client_callback(message)

    def _get_speech_client(self):
        # ... existing code ...
        pass

    def set_interview_question(self, question: str):
        """ç¾åœ¨ã®é¢æ¥ã®è³ªå•ã‚’è¨­å®šã™ã‚‹ã‚ˆã‚“ï¼"""
        self.current_interview_question = question
        logger.info(f"ğŸ¤ è¨­å®šã•ã‚ŒãŸé¢æ¥ã®è³ªå•: {question}")

    def _handle_emotion_data(self, emotion_data: dict):
        """
        SentimentWorkerã‹ã‚‰ã®æ„Ÿæƒ…åˆ†æçµæœã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã€‚
        Google Cloud Natural Language API ã®çµæœã«åˆã‚ã›ã¦èª¿æ•´ã—ãŸã‚ˆã‚“ï¼
        """
        # Natural Language API ã‹ã‚‰ã¯ score ã¨ magnitude ãŒãƒ¡ã‚¤ãƒ³ã§è¿”ã£ã¦ãã‚‹
        score = emotion_data.get("emotions", {}).get("score")
        magnitude = emotion_data.get("emotions", {}).get("magnitude")
        text_processed = emotion_data.get("text_processed", "")

        if score is not None and magnitude is not None:
            logger.info(f"ğŸ˜Š æ„Ÿæƒ…åˆ†æçµæœ (Google NL): ã‚¹ã‚³ã‚¢={score:.2f}, å¼·ã•={magnitude:.2f} (ãƒ†ã‚­ã‚¹ãƒˆ: '{text_processed[:50]}...')")
            # TODO: ã“ã®æƒ…å ±ã‚’ self.last_emotion_analysis_summary ã«é©åˆ‡ã«æ ¼ç´ã™ã‚‹
            # ä¾‹: self.last_emotion_analysis_summary = {"dominant_emotion": "è§£æãƒ­ã‚¸ãƒƒã‚¯", "score": score, "magnitude": magnitude, ...}
            # ä»Šå›ã¯å˜ç´”ã«æœ€æ–°ã®ã‚‚ã®ã‚’ä¿æŒã™ã‚‹ä¾‹
            self.last_emotion_analysis_summary = {
                "dominant_emotion": "ä¸æ˜ (Google NL score/magnitudeãƒ™ãƒ¼ã‚¹)",
                "emotion_score": score,
                "emotion_intensity": magnitude,
                "emotion_transition": "N/A (Google NLã¯ç™ºè©±å…¨ä½“)" # Google NLã®åŸºæœ¬APIã§ã¯æ¨ç§»ã¯å–ã‚Œãªã„
            }
        else:
            logger.warning(f"ğŸ¤” æ„Ÿæƒ…åˆ†æçµæœãŒä¸å®Œå…¨ã§ã™: {emotion_data}")

    async def _process_speech_stream(self):
        """
        ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Googleã«é€ã‚Šã€çµæœã‚’å‡¦ç†ã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã ã‚ˆã‚“ï¼
        WebSocketã‹ã‚‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ç”¨ã«èª¿æ•´ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
        """
        try:
            # 1. Google Speech-to-Text APIã«æ¥ç¶šã—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šã‚’é€ä¿¡
            stream_generator = self._microphone_stream_generator()
            # streaming_recognizeã¯ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’è¿”ã™ã‚³ãƒ«ãƒ¼ãƒãƒ³ãªã®ã§ã€awaitã§è§£æ±ºã™ã‚‹
            responses_iterator = await self.speech_client.streaming_recognize(requests=stream_generator)
            logger.info("âœ… Google Speech-to-Text APIã¨ã®æ¥ç¶šå®Œäº†ï¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹å¾…æ©Ÿä¸­...")

            # 2. ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹
            await self._start_workers()

            # 3. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’éåŒæœŸã§å‡¦ç†
            async for response in responses_iterator:
                if not self._is_running or self._stop_event.is_set():
                    logger.info("is_runningãŒFalseã¾ãŸã¯stop_eventãŒã‚»ãƒƒãƒˆã•ã‚ŒãŸãŸã‚ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                    break

                if not response.results:
                    continue

                result = response.results[0]
                if not result.alternatives:
                    continue

                transcript = result.alternatives[0].transcript
                
                # ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
                if self.sentiment_worker:
                    await self.sentiment_worker.add_text(transcript)

                if result.is_final:
                    logger.info(f"âœ… ç¢ºå®šã—ãŸæ–‡å­—èµ·ã“ã—: {transcript}")
                    # å…¨æ–‡æ–‡å­—èµ·ã“ã—ã‚’æ›´æ–°
                    self.full_transcript += transcript + " "
                    await self._send_to_client(
                        "final_transcript_segment", 
                        {"transcript": transcript}
                    )
                else:
                    # logger.info(f"ğŸ’¬ ä»®ã®æ–‡å­—èµ·ã“ã—: {transcript}")
                    await self._send_to_client(
                        "interim_transcript",
                        {"transcript": transcript}
                    )
        except asyncio.CancelledError:
            logger.info("ğŸš« _process_speech_stream ã‚¿ã‚¹ã‚¯ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ã¯é€Ÿã‚„ã‹ã«çµ‚äº†
            raise
        except StopAsyncIteration:
             logger.info("ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸã€‚")
        except exceptions.OutOfRange as e:
            # éŸ³å£°ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã‚’ã“ã“ã§ã‚­ãƒ£ãƒƒãƒï¼
            logger.error(f"ğŸ˜± éŸ³å£°ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            await self._send_to_client("error", {"message": "é•·æ™‚é–“éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"})
        except Exception as e:
            logger.error(f"ğŸ˜± _process_speech_streamã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}", exc_info=True)
            await self._send_to_client("error", {"message": f"éŸ³å£°å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"})
        finally:
            logger.info("ğŸ _process_speech_stream ãƒ«ãƒ¼ãƒ—ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚")
            # ã“ã“ã§ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ã™ã‚‹ã®ãŒç¢ºå®Ÿï¼
            await self._stop_workers()

    async def _microphone_stream_generator(self):
        """
        ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã£ã¦Google APIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã™ã‚‹éåŒæœŸã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã€‚
        WebSocketã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å…¥åŠ›ã«å¯¾å¿œã—ã¦ã‚‹ã‚ˆã‚“ï¼
        """
        # 1. æœ€åˆã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šã‚’é€ä¿¡
        recognition_config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=RATE,
            language_code="ja-JP",
            enable_automatic_punctuation=True,
            # ãƒ¢ãƒ‡ãƒ«é¸æŠ: 'telephony'ã‹'medical_conversation'ãªã©ãŒç”¨é€”ã«åˆã‚ã›ã¦é¸ã¹ã‚‹
            # 'default' ã‚‚ã‚ã‚‹ã‘ã©ã€ä»Šå›ã¯æ±ç”¨çš„ãª 'latest_long' ã‚’è©¦ã—ã¦ã¿ã‚‹
            model="latest_long", 
            use_enhanced=True, # é«˜åº¦ãªéŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’æœ‰åŠ¹åŒ–
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=recognition_config,
            interim_results=True,  # é€”ä¸­çµæœã‚’å–å¾—ã™ã‚‹
            single_utterance=False # è¤‡æ•°å›ã®ç™ºè©±ã‚’èªè­˜
        )
        yield speech.StreamingRecognizeRequest(streaming_config=streaming_config)
        logger.info("ğŸ¤ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šé€ä¿¡å®Œäº†ï¼éŸ³å£°å¾…æ©Ÿä¸­...")

        # 2. ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã£ã¦é€ä¿¡
        while self._is_running and not self._stop_event.is_set():
            try:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                chunk = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                yield speech.StreamingRecognizeRequest(audio_content=chunk)
            except asyncio.TimeoutError:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯ã‚¨ãƒ©ãƒ¼ã˜ã‚ƒãªã„ã€‚ãƒ‡ãƒ¼ã‚¿ãŒæ¥ã¦ãªã„ã ã‘ã ã‹ã‚‰ãƒ«ãƒ¼ãƒ—ã‚’ç¶šã‘ã‚‹
                continue
            except asyncio.CancelledError:
                logger.info("ğŸ¤ _microphone_stream_generatorãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
                break
        
        logger.info("ğŸ¤ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãŒçµ‚äº†ã—ã¾ã™ã€‚")

    def _microphone_worker(self):
        """
        PyAudioã‚’ä½¿ã£ã¦ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã—ã€éåŒæœŸã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•°ã€‚
        ã“ã‚Œã¯æ‰‹å‹•ãƒ†ã‚¹ãƒˆ (`manual_test_speech_processor.py`) ã®ãŸã‚ã®ã‚‚ã®ã ã‚ˆã‚“ï¼
        """
        p = self._get_pyaudio_instance()
        if not p:
            logger.error("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã€‚")
            return

        try:
            self.microphone_stream = p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
                stream_callback=self._microphone_callback
            )
            logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ãã¾ã—ãŸã€‚éŒ²éŸ³é–‹å§‹ï¼")

            while self.microphone_stream.is_active() and self._is_running:
                time.sleep(0.1)

        except Exception as e:
            logger.error(f"ğŸ˜± ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚ªãƒ¼ãƒ—ãƒ³ã¾ãŸã¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        finally:
            if self.microphone_stream:
                self.microphone_stream.stop_stream()
                self.microphone_stream.close()
                self.microphone_stream = None
                logger.info("ğŸ¤ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ãƒ»ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸã€‚")
            # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®çµ‚äº†ã¯ __del__ ã§è¡Œã†
            # p.terminate()

    def _microphone_callback(self, in_data, frame_count, time_info, status):
        """ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        # ã“ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã®ã§ã€éåŒæœŸã®putã§ã¯ãªãput_nowaitã‚’ä½¿ã†
        try:
            # process_audio_chunkã‚’ç›´æ¥å‘¼ã³å‡ºã™ã“ã¨ã§ãƒ”ãƒƒãƒè§£æã‚‚å®Ÿè¡Œ
            # ãŸã ã—ã€asyncé–¢æ•°ãªã®ã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã³å‡ºã™ã«ã¯å·¥å¤«ãŒå¿…è¦
            # ã“ã“ã§ã¯ event_loop ã‚’ä½¿ã£ã¦ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã™ã‚‹
            asyncio.run_coroutine_threadsafe(
                self.process_audio_chunk(in_data),
                self.main_loop
            )
        except Exception as e:
            logger.error(f"ãƒã‚¤ã‚¯ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã®ã‚­ãƒ¥ãƒ¼è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        return (in_data, pyaudio.paContinue)


    async def start_transcription_and_evaluation(self):
        """
        WebSocketã‹ã‚‰ã®éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ã‘ä»˜ã‘ã‚‹ãŸã‚ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ğŸ–¥ï¸ ã™ã§ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
            return

        logger.info("ğŸš€ WebSocketã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._stop_event.clear()
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ ---
        self.full_transcript = ""
        self.pitch_values = []
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        # --- ã“ã“ã¾ã§ ---

        self._processing_task = asyncio.create_task(self._process_speech_stream())
        logger.info("ğŸ”¥ ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")

    async def start_realtime_transcription_from_mic(self):
        """
        ã€æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã€‘ãƒã‚¤ã‚¯ã‹ã‚‰ç›´æ¥éŸ³å£°ã‚’å–å¾—ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if self._is_running:
            logger.warning("ğŸ™ï¸ ã™ã§ã«ãƒã‚¤ã‚¯ã‹ã‚‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
            return
        
        logger.info("ğŸš€ ãƒã‚¤ã‚¯ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
        self._is_running = True
        self._stop_event.clear()
        
        # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ ---
        self.full_transcript = ""
        self.pitch_values = []
        self.last_pitch_analysis_summary = {}
        self.last_emotion_analysis_summary = {}
        # --- ã“ã“ã¾ã§ ---

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚’å–å¾—
        self.main_loop = asyncio.get_running_loop()

        # ãƒã‚¤ã‚¯å…¥åŠ›ç”¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        self._microphone_task = threading.Thread(target=self._microphone_worker, daemon=True)
        self._microphone_task.start()
        
        # Speech-to-Textã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self._processing_task = asyncio.create_task(self._process_speech_stream())
        logger.info("ğŸ”¥ ãƒã‚¤ã‚¯éŸ³å£°ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")


    async def stop_transcription_and_evaluation(self):
        """
        æ–‡å­—èµ·ã“ã—ã¨è©•ä¾¡ã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã—ã€æœ€çµ‚è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆï¼
        """
        if not self._is_running:
            logger.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã™ã§ã«åœæ­¢ã—ã¦ã„ã¾ã™ã€‚")
            return
        
        logger.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³åœæ­¢ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...")

        # 1. ã¾ãšã¯æ–°ã—ã„éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘ä»˜ã‘ãªã„ã‚ˆã†ã«ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        self._is_running = False
        self._stop_event.set()

        # 2. éŸ³å£°ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã—ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«çµ‚äº†ã‚’é€šçŸ¥ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
        while not self._audio_queue.empty():
            self._audio_queue.get_nowait()
        await self._audio_queue.put(b"") #ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«çµ‚äº†ã•ã›ã‚‹

        # 3. ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        if self._processing_task and not self._processing_task.done():
            logger.info("ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™...")
            self._processing_task.cancel()
            try:
                await self._processing_task
            except asyncio.CancelledError:
                logger.info("ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¿ã‚¹ã‚¯ãŒæ­£å¸¸ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")

        # 4. ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ï¼ˆã“ã‚Œã¯_process_speech_streamã®finallyã§ã‚‚å‘¼ã°ã‚Œã‚‹ã‘ã©å¿µã®ãŸã‚ï¼‰
        await self._stop_workers()

        # 5. æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå‹•ã„ã¦ã„ãŸã‚‰åœæ­¢
        if self._microphone_task and self._microphone_task.is_alive():
            logger.info("æ‰‹å‹•ãƒ†ã‚¹ãƒˆç”¨ã®ãƒã‚¤ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã—ã¾ã™ã€‚")
            self._microphone_task.join()
            self._microphone_task = None

        logger.info("â³ å…¨ã¦ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚æœ€çµ‚è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™...")
        await self._send_to_client("evaluation_started", {})

        try:
            # 6. æœ€çµ‚è©•ä¾¡ã®å®Ÿè¡Œ
            final_evaluation = await self._run_final_evaluation()
            
            # 7. æœ€çµ‚è©•ä¾¡ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
            logger.info("ğŸ‘‘ æœ€çµ‚è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            # logger.debug(f"æœ€çµ‚è©•ä¾¡ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰: {final_evaluation}")
            await self._send_to_client("final_evaluation", {"evaluation": final_evaluation})
            
            # Geminiã‹ã‚‰ã®æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚‚é€ä¿¡
            if self.gemini_enabled and isinstance(final_evaluation, dict):
                 # `final_evaluation` ãŒè¾æ›¸ã§ã‚ã‚Šã€æœŸå¾…ã™ã‚‹ã‚­ãƒ¼ã‚’æŒã¤ã‹ç¢ºèª
                if "raw_evaluation" in final_evaluation and "score" in final_evaluation:
                    await self._send_to_client("gemini_feedback", final_evaluation)
                else:
                    # äº’æ›æ€§ã®ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    await self._send_to_client("gemini_feedback", {
                        "raw_evaluation": str(final_evaluation),
                        "score": 50 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
                    })

        except Exception as e:
            logger.error(f"ğŸ˜± æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            await self._send_to_client("error", {"message": "æœ€çµ‚è©•ä¾¡ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})
        
        logger.info("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸã€‚")


    async def _run_final_evaluation(self) -> dict | str:
        """
        ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†å¾Œã«ã€åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦Geminiã«æœ€çµ‚è©•ä¾¡ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã‚ˆï¼
        """
        logger.info("ğŸ§  Geminiã«ã‚ˆã‚‹æœ€çµ‚è©•ä¾¡ã‚’æº–å‚™ä¸­...")
        
        # åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒªãƒ¼
        self.last_pitch_analysis_summary = self._summarize_pitch_data()

        # Geminiã«æ¸¡ã™ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        evaluation_context = {
            "question": self.current_interview_question,
            "full_transcript": self.full_transcript,
            "pitch_analysis": self.last_pitch_analysis_summary,
            "emotion_analysis": self.last_emotion_analysis_summary
        }
        
        if self.gemini_enabled:
            try:
                # gemini_service ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™
                response_data = await gemini_service.generate_structured_feedback(evaluation_context)
                logger.info("ğŸ’ Geminiã‹ã‚‰è©•ä¾¡ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
                # response_data ã¯æ—¢ã«è¾æ›¸ã®ã¯ãš
                return response_data
            except Exception as e:
                logger.error(f"ğŸ˜± Geminiã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                return f"Geminiè©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        else:
            logger.warning("ğŸ˜¢ GeminiãŒç„¡åŠ¹ãªãŸã‚ã€æœ€çµ‚è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return "Geminiè©•ä¾¡ã¯ç¾åœ¨ç„¡åŠ¹ã§ã™ã€‚"


    def _summarize_pitch_data(self):
        """ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã™ã‚‹ã‚ˆ"""
        if not self.pitch_values:
            logger.info("ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ãŒåé›†ã•ã‚Œãªã‹ã£ãŸã®ã§ã€ãƒ”ãƒƒãƒã®è¦ç´„ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return {}

        # npã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        try:
            import numpy as np
        except ImportError:
            logger.warning("numpyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ”ãƒƒãƒã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
            return {}

        try:
            pitches = np.array(self.pitch_values)
            average_pitch = np.mean(pitches)
            pitch_variation = np.std(pitches)
            
            summary = {
                "average_pitch": f"{average_pitch:.2f}",
                "pitch_variation": f"{pitch_variation:.2f}",
            }
            return summary
        except Exception as e:
            logger.error(f"ãƒ”ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {}


    def __del__(self):
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒç ´æ£„ã•ã‚Œã‚‹ã¨ãã«PyAudioã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.pyaudio_instance:
            logger.info("PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£æ”¾ã—ã¾ã™ã€‚")
            self.pyaudio_instance.terminate()
            self.pyaudio_instance = None