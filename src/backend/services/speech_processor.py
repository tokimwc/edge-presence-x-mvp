# ã“ã“ã« Google Cloud Speech-to-Text ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹æ„Ÿã˜ã§ï¼
from google.cloud import speech_v1p1beta1 as speech # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ã†ã‚ˆï¼
import asyncio
import pyaudio
import logging # logging ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os # ç’°å¢ƒå¤‰æ•°ã®ãŸã‚ã«è¿½åŠ 

# --- Pythonã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œç´¢ãƒ‘ã‚¹ã«srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ  ---
import sys
# speech_processor.py ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (src/backend/services)
_CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ (src/backend/services -> src/backend -> src)
_SRC_DIR = os.path.abspath(os.path.join(_CURRENT_FILE_DIR, '..', '..'))
if _SRC_DIR not in sys.path:
    sys.path.insert(0, _SRC_DIR)
# --- ã“ã“ã¾ã§ ---

# Worker ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (ç›¸å¯¾ãƒ‘ã‚¹ã‹ã‚‰srcã‚’åŸºæº–ã¨ã—ãŸçµ¶å¯¾ãƒ‘ã‚¹é¢¨ã«å¤‰æ›´)
from backend.workers.pitch_worker import PitchWorker
from backend.workers.sentiment_worker import SentimentWorker # SentimentWorker ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# logging ã®åŸºæœ¬è¨­å®š (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ï¼‘å›ã ã‘å®Ÿè¡Œ)
# SpeechProcessor ã‚¯ãƒ©ã‚¹ã®å¤–ã§è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ã‚ˆã‚“ï¼
logging.basicConfig(
    level=logging.INFO,  # é–‹ç™ºä¸­ã¯INFOãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã‚’è¡¨ç¤º
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
# ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = logging.getLogger(__name__)

# PyAudioã®è¨­å®š (ã“ã‚Œã‚‰ã®å€¤ã¯ãƒã‚¤ã‚¯ã‚„è¦ä»¶ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ã­ï¼)
FORMAT = pyaudio.paInt16  # éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (16bit)
CHANNELS = 1             # ãƒ¢ãƒãƒ©ãƒ«
RATE = 16000             # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ (16kHz)
CHUNK = int(RATE / 10)   # 100msåˆ†ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º (Speech-to-Textã®æ¨å¥¨ã«åˆã‚ã›ã¦)
SAMPLE_WIDTH = pyaudio.PyAudio().get_sample_size(FORMAT) # PyAudioã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«å¹…ã‚’å–å¾—

# --- Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®è¿½åŠ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨è¨­å®š ---
import json
from vertexai.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold
import vertexai # vertexaiã®ãƒ¡ã‚¤ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# Geminiè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (speech_processor.pyã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’è€ƒæ…®)
# _SRC_DIR ã¯ src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡ã™ã®ã§ã€ãã“ã‹ã‚‰ä¸€ã¤ä¸ŠãŒã£ã¦ config ã‚’æŒ‡å®š
GEMINI_CONFIG_PATH = os.path.join(_SRC_DIR, "..", "config", "gemini_config.json")

PROMPT_TEMPLATE = """
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼šAIé¢æ¥è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 

ã‚ãªãŸã¯ã€çµŒé¨“è±Šå¯Œãªã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã‚ã‚Šã€è¡Œå‹•é¢æ¥ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚
ç‰¹ã«STARæ‰‹æ³•ã‚’ç”¨ã„ãŸå›ç­”ã®åˆ†æã¨ã€å£°ã®ãƒˆãƒ¼ãƒ³ã‚„æ„Ÿæƒ…è¡¨ç¾ã‹ã‚‰å€™è£œè€…ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³èƒ½åŠ›ã‚’è¦‹æŠœãã“ã¨ã«é•·ã‘ã¦ã„ã¾ã™ã€‚
æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ãã€é¢æ¥ã®å›ç­”ã‚’å¤šè§’çš„ã«è©•ä¾¡ã—ã€å…·ä½“çš„ã‹ã¤å»ºè¨­çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

## å…¥åŠ›æƒ…å ±

### é¢æ¥ã®è³ªå•:
```
{interview_question}
```

### å›ç­”ã®æ–‡å­—èµ·ã“ã—:
```
{transcript}
```

### ãƒ”ãƒƒãƒè§£æçµæœ:
- å¹³å‡ãƒ”ãƒƒãƒ: {average_pitch} Hz
- ãƒ”ãƒƒãƒã®å¤‰å‹•å¹…: {pitch_range} Hz
- è©±ã™é€Ÿåº¦: {speaking_rate} æ–‡å­—/åˆ†
- ãƒãƒ¼ã‚ºã®é »åº¦: {pause_frequency} å›/åˆ†
- ãƒãƒ¼ã‚ºã®å¹³å‡æ™‚é–“: {average_pause_duration} ç§’

### æ„Ÿæƒ…åˆ†æçµæœ:
- ä¸»ãªæ„Ÿæƒ…: {dominant_emotion}
- æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ ({dominant_emotion}): {emotion_score}
- æ„Ÿæƒ…ã®å¼·ã•: {emotion_intensity}
- ç™ºè©±ä¸­ã®æ„Ÿæƒ…ã®æ¨ç§»: {emotion_transition}

## è©•ä¾¡åŸºæº–

### 1. STARæ‰‹æ³•ã®è©•ä¾¡
*   **Situationï¼ˆçŠ¶æ³ï¼‰:**
    *   å…·ä½“çš„ãªçŠ¶æ³èª¬æ˜ãŒæ˜ç¢ºã«ãªã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    *   å›ç­”è€…ãŒã©ã®ã‚ˆã†ãªçŠ¶æ³ã«ç½®ã‹ã‚Œã¦ã„ãŸã®ã‹ã€èƒŒæ™¯æƒ…å ±ãŒååˆ†ã«æä¾›ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    *   ã„ã¤ã€ã©ã“ã§ã€èª°ãŒé–¢ã‚ã£ã¦ã„ãŸã®ã‹ãŒæ˜ç¢ºã‹ï¼Ÿ
*   **Taskï¼ˆèª²é¡Œï¼‰:**
    *   å–ã‚Šçµ„ã‚€ã¹ãèª²é¡Œã‚„ç›®æ¨™ãŒæ˜ç¢ºã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    *   ãã®èª²é¡Œã®é‡è¦æ€§ã‚„å›°é›£åº¦ãŒä¼ã‚ã‚‹ã‹ï¼Ÿ
    *   ä½•ã‚’é”æˆã™ã‚‹å¿…è¦ãŒã‚ã£ãŸã®ã‹ãŒå…·ä½“çš„ã‹ï¼Ÿ
*   **Actionï¼ˆè¡Œå‹•ï¼‰:**
    *   èª²é¡Œè§£æ±ºã®ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã¦ã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚’å–ã£ãŸã®ã‹èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    *   è¡Œå‹•ã®ä¸»ä½“ã¯å›ç­”è€…è‡ªèº«ã‹ï¼Ÿ
    *   è¡Œå‹•ã®ç†ç”±ã‚„ç›®çš„ãŒæ˜ç¢ºã‹ï¼Ÿ
    *   è¤‡æ•°ã®è¡Œå‹•ãŒã‚ã‚‹å ´åˆã€ãã‚Œã‚‰ãŒè«–ç†çš„ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
*   **Resultï¼ˆçµæœï¼‰:**
    *   è¡Œå‹•ã®çµæœã€ã©ã®ã‚ˆã†ãªå…·ä½“çš„ãªæˆæœãŒå¾—ã‚‰ã‚ŒãŸã®ã‹æ˜ç¢ºã«èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    *   å¯èƒ½ãªé™ã‚Šå®šé‡çš„ãªãƒ‡ãƒ¼ã‚¿ï¼ˆæ•°å€¤ã€å‰²åˆãªã©ï¼‰ã‚’ç”¨ã„ã¦æˆæœã‚’ç¤ºã›ã¦ã„ã‚‹ã‹ï¼Ÿ
    *   çµæœã‹ã‚‰ä½•ã‚’å­¦ã³ã€æ¬¡ã«ã©ã†æ´»ã‹ãã†ã¨ã—ã¦ã„ã‚‹ã‹ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    *   ãƒã‚¸ãƒ†ã‚£ãƒ–ãªçµæœã ã‘ã§ãªãã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãªçµæœã‚„ãã“ã‹ã‚‰ã®å­¦ã³ã‚‚ã‚ã‚Œã°è©•ä¾¡ã™ã‚‹ã€‚

### 2. å›ç­”ã®æ§‹é€ 
*   **è«–ç†æ€§ã¨æ§‹æˆ:**
    *   å›ç­”å…¨ä½“ãŒè«–ç†çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ§‹æˆã«ãªã£ã¦ã„ã‚‹ã‹ï¼Ÿ (ä¾‹: PREPæ³•ã€æ™‚ç³»åˆ—ãªã©)
    *   è©±ã®å°å…¥ã€æœ¬è«–ã€çµè«–ãŒæ˜ç¢ºã‹ï¼Ÿ
    *   å†—é•·ãªéƒ¨åˆ†ã‚„è©±ãŒé£›èºã—ã¦ã„ã‚‹ç®‡æ‰€ã¯ãªã„ã‹ï¼Ÿ
*   **å…·ä½“æ€§:**
    *   æŠ½è±¡çš„ãªè¡¨ç¾ã«çµ‚å§‹ã›ãšã€å…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚„äº‹ä¾‹ã‚’äº¤ãˆã¦èª¬æ˜ã§ãã¦ã„ã‚‹ã‹ï¼Ÿ
    *   èª°ãŒèã„ã¦ã‚‚æƒ…æ™¯ã‚’ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ãã‚‹ã‚ˆã†ãªè©³ç´°ã•ãŒã‚ã‚‹ã‹ï¼Ÿ

### 3. å£°ã®ãƒˆãƒ¼ãƒ³ã¨è©±ã—æ–¹
*   **è‡ªä¿¡ã¨ç†±æ„:**
    *   å£°ã®ãƒˆãƒ¼ãƒ³ã¯å®‰å®šã—ã¦ãŠã‚Šã€è‡ªä¿¡ãŒæ„Ÿã˜ã‚‰ã‚Œã‚‹ã‹ï¼Ÿ
    *   èªå°¾ãŒæ˜ç­ã§ã€ãƒã‚­ãƒã‚­ã¨è©±ã›ã¦ã„ã‚‹ã‹ï¼Ÿ
    *   è©±ã®å†…å®¹ã«å¯¾ã™ã‚‹ç†±æ„ã‚„æ„æ¬²ãŒå£°ã‹ã‚‰ä¼ã‚ã‚‹ã‹ï¼Ÿ
    *   æ—©å£ã™ããŸã‚Šã€é€†ã«é…ã™ãã¦é–“å»¶ã³ã—ã¦ã„ãªã„ã‹ï¼Ÿ
*   **èãå–ã‚Šã‚„ã™ã•:**
    *   å£°é‡ã‚„æ»‘èˆŒã¯é©åˆ‡ã§ã€èãå–ã‚Šã‚„ã™ã„è©±ã—æ–¹ã‹ï¼Ÿ
    *   ä¸è¦ãªã€Œãˆãƒ¼ã£ã¨ã€ã€Œã‚ã®ãƒ¼ã€ãªã©ã®ãƒ•ã‚£ãƒ©ãƒ¼ãŒå¤šã™ããªã„ã‹ï¼Ÿ

### 4. æ„Ÿæƒ…è¡¨ç¾
*   **é©åˆ‡æ€§ã¨ä¸€è²«æ€§:**
    *   è©±ã®å†…å®¹ã¨æ„Ÿæƒ…è¡¨ç¾ï¼ˆå£°ã®ãƒˆãƒ¼ãƒ³ã€è©±ã™é€Ÿåº¦ãªã©ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹ã‚‚ã®ï¼‰ãŒä¸€è²«ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
    *   å ´é¢ã«å¿œã˜ãŸé©åˆ‡ãªæ„Ÿæƒ…ãŒè¡¨ç¾ã§ãã¦ã„ã‚‹ã‹ï¼Ÿï¼ˆä¾‹ï¼šå›°é›£ã‚’èªã‚‹éš›ã¯çœŸå‰£ãªãƒˆãƒ¼ãƒ³ã€æˆåŠŸã‚’èªã‚‹éš›ã¯æ˜ã‚‹ã„ãƒˆãƒ¼ãƒ³ãªã©ï¼‰
    *   æ„Ÿæƒ…ã®èµ·ä¼ãŒæ¿€ã—ã™ããŸã‚Šã€é€†ã«ä¹ã—ã™ããŸã‚Šã—ãªã„ã‹ï¼Ÿ

### 5. å…¨ä½“çš„ãªå°è±¡
*   **åˆ†ã‹ã‚Šã‚„ã™ã•:**
    *   å›ç­”å…¨ä½“ã‚’é€šã—ã¦ã€ä¼ãˆãŸã„ã“ã¨ãŒæ˜ç¢ºã«ä¼ã‚ã£ã¦ãã‚‹ã‹ï¼Ÿ
    *   å°‚é–€ç”¨èªã‚’ä½¿ã„ã™ããšã€ç›¸æ‰‹ã«é…æ…®ã—ãŸè¨€è‘‰é£ã„ãŒã§ãã¦ã„ã‚‹ã‹ï¼Ÿ
*   **èª¬å¾—åŠ›:**
    *   è‡ªå·±PRã‚„çµŒé¨“è«‡ã«èª¬å¾—åŠ›ãŒã‚ã‚Šã€èãæ‰‹ã‚’ç´å¾—ã•ã›ã‚‰ã‚Œã‚‹ã‹ï¼Ÿ
    *   æ ¹æ‹ ã«åŸºã¥ã„ãŸä¸»å¼µãŒã§ãã¦ã„ã‚‹ã‹ï¼Ÿ
*   **ç†±æ„ã¨æ„æ¬²:**
    *   ãã®ä¼æ¥­ã‚„è·å‹™ã«å¯¾ã™ã‚‹ç†±æ„ã‚„å…¥ç¤¾æ„æ¬²ãŒæ„Ÿã˜ã‚‰ã‚Œã‚‹ã‹ï¼Ÿ
    *   ãƒã‚¸ãƒ†ã‚£ãƒ–ãªå§¿å‹¢ã§é¢æ¥ã«è‡¨ã‚“ã§ã„ã‚‹ã‹ï¼Ÿ

## å‡ºåŠ›å½¢å¼

### 1. ç·åˆè©•ä¾¡ (5æ®µéš)
1.  æ”¹å–„ãŒå¿…è¦
2.  ã¾ã æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹
3.  è‰¯ã„
4.  éå¸¸ã«è‰¯ã„
5.  ç´ æ™´ã‚‰ã—ã„

### 2. å„è©•ä¾¡é …ç›®ã®è©³ç´°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
*   **STARæ‰‹æ³•:**
    *   Situation: ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ï¼‰
    *   Task: ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ï¼‰
    *   Action: ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ï¼‰
    *   Result: ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ï¼‰
*   **å›ç­”ã®æ§‹é€ :** ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ï¼‰
*   **å£°ã®ãƒˆãƒ¼ãƒ³ã¨è©±ã—æ–¹:** ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ã€ãƒ”ãƒƒãƒè§£æçµæœã‚’å…ƒã«ï¼‰
*   **æ„Ÿæƒ…è¡¨ç¾:** ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ã€æ„Ÿæƒ…åˆ†æçµæœã‚’å…ƒã«ï¼‰
*   **å…¨ä½“çš„ãªå°è±¡:** ï¼ˆå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ç‚¹ï¼‰

### 3. å›ç­”å…¨ä½“ã®æ”¹å–„ç‚¹ (3ã¤ç¨‹åº¦)
1.  ï¼ˆå…·ä½“çš„ãªæ”¹å–„ç‚¹ï¼‰
2.  ï¼ˆå…·ä½“çš„ãªæ”¹å–„ç‚¹ï¼‰
3.  ï¼ˆå…·ä½“çš„ãªæ”¹å–„ç‚¹ï¼‰

### 4. ã‚¢ãƒ”ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒˆ (3ã¤ç¨‹åº¦)
1.  ï¼ˆç‰¹ã«å„ªã‚Œã¦ã„ã‚‹ç‚¹ã€å¼·ã¿ã¨ãªã‚‹ç‚¹ï¼‰
2.  ï¼ˆç‰¹ã«å„ªã‚Œã¦ã„ã‚‹ç‚¹ã€å¼·ã¿ã¨ãªã‚‹ç‚¹ï¼‰
3.  ï¼ˆç‰¹ã«å„ªã‚Œã¦ã„ã‚‹ç‚¹ã€å¼·ã¿ã¨ãªã‚‹ç‚¹ï¼‰

## æŒ‡ç¤º

ä¸Šè¨˜ã®å…¥åŠ›æƒ…å ±ã¨è©•ä¾¡åŸºæº–ã«åŸºã¥ãã€é¢æ¥ã®å›ç­”ã‚’è©³ç´°ã«åˆ†æãƒ»è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
ãã—ã¦ã€å®šç¾©ã•ã‚ŒãŸå‡ºåŠ›å½¢å¼ã«å¾“ã£ã¦ã€ç·åˆè©•ä¾¡ã€å„è©•ä¾¡é …ç›®ã®è©³ç´°ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€å›ç­”å…¨ä½“ã®æ”¹å–„ç‚¹ã€ãŠã‚ˆã³ã‚¢ãƒ”ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã€å…·ä½“çš„ã§ã€å€™è£œè€…ãŒæ¬¡ã®é¢æ¥ã«æ´»ã‹ã›ã‚‹ã‚ˆã†ãªå®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚

## åˆ¶ç´„
*   å€‹äººã‚’ç‰¹å®šã§ãã‚‹æƒ…å ±ï¼ˆæ°åã€å…·ä½“çš„ãªä¼æ¥­åã€è£½å“åãªã©ã€ä¸€èˆ¬çš„ã«å…¬é–‹ã•ã‚Œã¦ã„ãªã„æƒ…å ±ï¼‰ã‚’ç”Ÿæˆã€ã¾ãŸã¯æ¨æ¸¬ã—ã¦å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚
*   ã„ã‹ãªã‚‹å½¢ã§ã‚ã‚Œã€å·®åˆ¥çš„ãªè¡¨ç¾ã‚„ã€ç‰¹å®šã®å€‹äººãƒ»å›£ä½“ã‚’ä¸å½“ã«è²¶ã‚ã‚‹ã‚ˆã†ãªå†…å®¹ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
*   æä¾›ã•ã‚ŒãŸæƒ…å ±ã®ã¿ã«åŸºã¥ã„ã¦è©•ä¾¡ã‚’è¡Œã„ã€æ†¶æ¸¬ã‚„å€‹äººçš„ãªåè¦‹ã‚’æ’é™¤ã—ã¦ãã ã•ã„ã€‚
*   æ³•å¾‹ã‚„å€«ç†ã«åã™ã‚‹ã‚ˆã†ãªä¸é©åˆ‡ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¯è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚
*   ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯å®¢è¦³çš„ã‹ã¤å»ºè¨­çš„ãªã‚‚ã®ã«çµ‚å§‹ã—ã¦ãã ã•ã„ã€‚
"""

gemini_model_instance = None # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦Geminiãƒ¢ãƒ‡ãƒ«ã‚’ä¿æŒï¼ˆã‚¯ãƒ©ã‚¹å†…ã§ç®¡ç†æ¨å¥¨ï¼‰
gemini_config_data = None    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦Geminiè¨­å®šã‚’ä¿æŒ

def load_gemini_config_and_init():
    global gemini_model_instance, gemini_config_data
    if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        logger.warning(
            "ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            "Vertex AI APIã¸ã®èªè¨¼ã«å¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        )
        # raise EnvironmentError("GOOGLE_APPLICATION_CREDENTIALS is not set.") # å¿…è¦ãªã‚‰ã‚¨ãƒ©ãƒ¼ã«ã™ã‚‹
        return False # èªè¨¼æƒ…å ±ãŒãªã„å ´åˆã¯Falseã‚’è¿”ã™

    try:
        with open(GEMINI_CONFIG_PATH, 'r') as f:
            gemini_config_data = json.load(f)
        logger.info(f"Geminiè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {GEMINI_CONFIG_PATH}")

        # project_id -> project ã«å¤‰æ›´ï¼ã›ã‚“ã±ã„ã®è¨­å®šã«åˆã‚ã›ãŸã‚ˆã‚“ï¼
        vertexai.init(project=gemini_config_data["project"], location=gemini_config_data["location"])
        gemini_model_instance = GenerativeModel(
            gemini_config_data["model_name"],
            # ã›ã‚“ã±ã„ãŒè¨­å®šã—ã¦ãã‚ŒãŸ generation_config ã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ã—ãŸã‚ˆï¼
            generation_config=gemini_config_data.get("generation_config", {}),
            # å®‰å…¨æ€§è¨­å®šã®ä¾‹ (å¿…è¦ã«å¿œã˜ã¦èª¿æ•´)
            # safety_settings={
            #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            #     HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            # }
        )
        logger.info(f"Geminiãƒ¢ãƒ‡ãƒ« ({gemini_config_data['model_name']}) ã®æº–å‚™ãŒã§ãã¾ã—ãŸã€‚")
        return True
    except FileNotFoundError:
        logger.error(f"Geminiè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {GEMINI_CONFIG_PATH}")
    except Exception as e:
        logger.error(f"Geminiè¨­å®šã®èª­ã¿è¾¼ã¿ã¾ãŸã¯åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    return False

async def get_gemini_evaluation(
    interview_question: str,
    transcript: str,
    pitch_analysis: dict,
    emotion_analysis: dict
) -> str | None:
    if not gemini_model_instance or not gemini_config_data:
        logger.error("Geminiãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None

    prompt = PROMPT_TEMPLATE.format(
        interview_question=interview_question,
        transcript=transcript,
        average_pitch=pitch_analysis.get("average_pitch", "N/A"),
        pitch_range=pitch_analysis.get("pitch_range", "N/A"),
        speaking_rate=pitch_analysis.get("speaking_rate", "N/A"),
        pause_frequency=pitch_analysis.get("pause_frequency", "N/A"),
        average_pause_duration=pitch_analysis.get("average_pause_duration", "N/A"),
        dominant_emotion=emotion_analysis.get("dominant_emotion", "N/A"),
        emotion_score=emotion_analysis.get("emotion_score", "N/A"),
        emotion_intensity=emotion_analysis.get("emotion_intensity", "N/A"),
        emotion_transition=emotion_analysis.get("emotion_transition", "N/A")
    )
    logger.info("Geminiã¸ã®è©•ä¾¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚")

    try:
        response = await gemini_model_instance.generate_content_async(prompt)
        if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
            evaluation_text = response.candidates[0].content.parts[0].text
            logger.info("Geminiã‹ã‚‰é¢æ¥è©•ä¾¡ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚")
            return evaluation_text
        else:
            logger.warning("Geminiã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«æœ‰åŠ¹ãªè©•ä¾¡ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return "è©•ä¾¡çµæœã®å½¢å¼ãŒç„¡åŠ¹ã§ã™ã€‚"
    except Exception as e:
        logger.error(f"Gemini APIãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return f"Gemini APIã‚¨ãƒ©ãƒ¼: {str(e)}"

def parse_gemini_response_data(response_text: str) -> dict:
    """Geminiã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹é–¢æ•° (ä»Šå›ã¯æœªå®Ÿè£…ã€ç”Ÿã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™)"""
    logger.info("Geminiãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹å‡¦ç† (ç¾åœ¨ã¯ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã—ã¾ã™)")
    return {"raw_evaluation": response_text}

# --- ã“ã“ã¾ã§Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®è¿½åŠ  ---

class SpeechProcessor:
    def __init__(self):
        self.speech_client = speech.SpeechAsyncClient()
        self.pyaudio_instance = pyaudio.PyAudio()
        self._audio_queue = asyncio.Queue()
        self._is_running = False
        self._microphone_task = None
        self._stop_event = asyncio.Event()
        self.main_loop = asyncio.get_event_loop()

        # PitchWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            self.pitch_worker = PitchWorker(
                sample_rate=RATE,
                channels=CHANNELS,
                sample_width=SAMPLE_WIDTH,
            )
            logger.info("ğŸµ PitchWorker ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± PitchWorker ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.pitch_worker = None

        # SentimentWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            # Google Cloud Natural Language API ã‚’ä½¿ã†ã®ã§ã€APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ã§è¨­å®šã•ã‚Œã¦ã‚‹å‰æã ã‚ˆã‚“ï¼
            self.sentiment_worker = SentimentWorker(
                on_emotion_callback=self._handle_emotion_data,
                language_code="ja" # Google Cloud NL API ã¯ "ja" ã‚’ä½¿ã†ã‚ˆï¼
            )
            logger.info("ğŸ˜Š SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e: # SentimentWorkerå†…ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã‚‚ã‚­ãƒ£ãƒƒãƒã§ãã‚‹ã‚ˆã†ã«æ±ç”¨çš„ãªExceptionã«
            logger.exception("ğŸ˜± SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.sentiment_worker = None

        logger.info("âœ¨ SpeechProcessor åˆæœŸåŒ–å®Œäº†ï¼âœ¨")
        logger.info(f"PyAudioè¨­å®š: FORMAT={FORMAT}, CHANNELS={CHANNELS}, RATE={RATE}, CHUNK={CHUNK}, SAMPLE_WIDTH={SAMPLE_WIDTH}")

        # --- Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®åˆæœŸåŒ– ---
        self.gemini_enabled = load_gemini_config_and_init()
        if self.gemini_enabled:
            logger.info("ğŸ‘‘ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸã€‚")
        else:
            logger.warning("ğŸ˜¢ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã¯ç„¡åŠ¹ã§ã™ã€‚è¨­å®šã¾ãŸã¯èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        self.current_interview_question = "è‡ªå·±PRã‚’ã—ã¦ãã ã•ã„ã€‚" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•
        self.last_pitch_analysis_summary = {} # ãƒ”ãƒƒãƒè§£æã®é›†è¨ˆçµæœã‚’ä¿æŒã™ã‚‹å ´æ‰€ (TODO: PitchWorkerã¨é€£æº)
        self.last_emotion_analysis_summary = {} # æ„Ÿæƒ…åˆ†æã®é›†è¨ˆçµæœã‚’ä¿æŒã™ã‚‹å ´æ‰€ (TODO: SentimentWorkerã¨é€£æº)
        # --- ã“ã“ã¾ã§Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®åˆæœŸåŒ– ---

    def _handle_emotion_data(self, emotion_data: dict):
        """
        SentimentWorkerã‹ã‚‰ã®æ„Ÿæƒ…åˆ†æçµæœã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã€‚
        Google Cloud Natural Language API ã®çµæœã«åˆã‚ã›ã¦èª¿æ•´ã—ãŸã‚ˆã‚“ï¼
        """
        # Natural Language API ã‹ã‚‰ã¯ score ã¨ magnitude ãŒãƒ¡ã‚¤ãƒ³ã§è¿”ã£ã¦ãã‚‹
        score = emotion_data.get("emotions", {}).get("score")
        magnitude = emotion_data.get("emotions", {}).get("magnitude")
        text_processed = emotion_data.get("text_processed", "")

        if score is not None and magnitude is not None:
            logger.info(f"ğŸ˜Š æ„Ÿæƒ…åˆ†æçµæœ (Google NL): ã‚¹ã‚³ã‚¢={score:.2f}, å¼·ã•={magnitude:.2f} (ãƒ†ã‚­ã‚¹ãƒˆ: '{text_processed[:50]}...')")
            # TODO: ã“ã®æƒ…å ±ã‚’ self.last_emotion_analysis_summary ã«é©åˆ‡ã«æ ¼ç´ã™ã‚‹
            # ä¾‹: self.last_emotion_analysis_summary = {"dominant_emotion": "è§£æãƒ­ã‚¸ãƒƒã‚¯", "score": score, "magnitude": magnitude, ...}
            # ä»Šå›ã¯å˜ç´”ã«æœ€æ–°ã®ã‚‚ã®ã‚’ä¿æŒã™ã‚‹ä¾‹
            self.last_emotion_analysis_summary = {
                "dominant_emotion": "ä¸æ˜ (Google NL score/magnitudeãƒ™ãƒ¼ã‚¹)",
                "emotion_score": score,
                "emotion_intensity": magnitude,
                "emotion_transition": "N/A (Google NLã¯ç™ºè©±å…¨ä½“)" # Google NLã®åŸºæœ¬APIã§ã¯æ¨ç§»ã¯å–ã‚Œãªã„
            }
        else:
            logger.warning(f"ğŸ¤” æ„Ÿæƒ…åˆ†æçµæœãŒä¸å®Œå…¨ã§ã™: {emotion_data}")

    async def _microphone_stream_generator(self):
        """
        ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’éåŒæœŸã§ä¾›çµ¦ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã ã‚ˆã‚“ï¼
        Speech-to-Text API ãŒæœŸå¾…ã™ã‚‹ StreamingRecognitionConfig ã¨éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ yield ã™ã‚‹ã€‚
        """
        streaming_config = speech.StreamingRecognitionConfig(
            config=speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=RATE,
                language_code="ja-JP",
                enable_automatic_punctuation=True,
            ),
            interim_results=True,
        )
        yield speech.StreamingRecognizeRequest(streaming_config=streaming_config)
        logger.info("ğŸ¤ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šé€ä¿¡å®Œäº†ï¼éŸ³å£°å¾…æ©Ÿä¸­...")

        while self._is_running and not self._stop_event.is_set():
            try:
                chunk = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                if chunk is None: 
                    break
                yield speech.StreamingRecognizeRequest(audio_content=chunk)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.exception("ğŸ˜± _microphone_stream_generator ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼")
                break
        logger.info("ğŸ¤ _microphone_stream_generator çµ‚äº†")

    def _microphone_worker(self):
        """
        PyAudioã‚’ä½¿ã£ã¦ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹åŒæœŸå‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ã€‚
        ã“ã‚Œã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹æƒ³å®šã ã‚ˆã‚“ï¼
        """
        try:
            stream = self.pyaudio_instance.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
            )
            logger.info("ğŸ™ï¸ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹ï¼ éŸ³å£°åé›†ä¸­...")
            data_counter = 0 # ãƒ‡ãƒãƒƒã‚°ç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            while self._is_running and not self._stop_event.is_set():
                try:
                    data = stream.read(CHUNK, exception_on_overflow=False)
                    data_counter += 1
                    
                    log_pitch_str = "N/A"
                    if self.pitch_worker and data:
                        try:
                            pitch_hz = self.pitch_worker.analyze_pitch(data)
                            if pitch_hz is not None:
                                log_pitch_str = f"{pitch_hz:.2f} Hz"
                                # TODO: ãƒ”ãƒƒãƒæƒ…å ±ã‚’ self.last_pitch_analysis_summary ã«é›†è¨ˆãƒ»æ ¼ç´ã™ã‚‹
                                # ä¾‹: å¹³å‡ãƒ”ãƒƒãƒã€å¤‰å‹•å¹…ãªã©ã‚’è¨ˆç®—ã—ã¦ä¿æŒ
                                # ä»Šå›ã¯ãƒ€ãƒŸãƒ¼ã¨ã—ã¦æœ€æ–°ã®ãƒ”ãƒƒãƒã‚’ä¸€æ™‚çš„ã«ä¿æŒã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ (å®Ÿéš›ã«ã¯é›†è¨ˆãŒå¿…è¦)
                                if "pitches" not in self.last_pitch_analysis_summary:
                                    self.last_pitch_analysis_summary["pitches"] = []
                                self.last_pitch_analysis_summary["pitches"].append(pitch_hz)
                                if len(self.last_pitch_analysis_summary["pitches"]) > 100: # æœ€æ–°100ä»¶ä¿æŒãªã©
                                     self.last_pitch_analysis_summary["pitches"].pop(0)

                        except Exception as e:
                            logger.error(f"ğŸ˜± (Worker) PitchWorkerã§ã®ãƒ”ãƒƒãƒè§£æã‚¨ãƒ©ãƒ¼: {e}")
                            log_pitch_str = "Error"

                    logger.debug(f"ğŸ¤ [Worker-{data_counter}] ãƒãƒ£ãƒ³ã‚¯å—ä¿¡ï¼ ã‚µã‚¤ã‚º: {len(data)}, å…ˆé ­10ãƒã‚¤ãƒˆ: {data[:10].hex() if data else 'None'} | ğŸµ ãƒ”ãƒƒãƒ: {log_pitch_str}")
                    
                    asyncio.run_coroutine_threadsafe(self._audio_queue.put(data), self.main_loop)
                except IOError as e:
                    logger.warning(f"ğŸ¤ PyAudio readã‚¨ãƒ©ãƒ¼ (ãŸã¶ã‚“ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼): {e}") 
                    asyncio.run_coroutine_threadsafe(asyncio.sleep(0.01), self.main_loop)
                except Exception as e:
                    logger.exception(f"ğŸ˜± _microphone_workerã®å†…éƒ¨ãƒ«ãƒ¼ãƒ—ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ«ãƒ¼ãƒ—ã‚’ç¶™ç¶šã™ã‚‹ãŸã‚ã« à´šàµ†à´±à´¿à´¯å¾…æ©Ÿæ™‚é–“ã‚’è¨­ã‘ã‚‹ã“ã¨ã‚‚æ¤œè¨
                    asyncio.run_coroutine_threadsafe(asyncio.sleep(0.01), self.main_loop)

            logger.info("ğŸ™ï¸ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ«ãƒ¼ãƒ—çµ‚äº†ã€‚ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢å‡¦ç†ã¸...")
            stream.stop_stream()
            stream.close()
            logger.info("ğŸ™ï¸ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ æ­£å¸¸çµ‚äº†ã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± _microphone_workerã§è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼")
        finally:
            if self._is_running: 
                 logger.info("_microphone_worker ã® finally ã§ã‚­ãƒ¥ãƒ¼ã«Noneã‚’é€ä¿¡")
                 asyncio.run_coroutine_threadsafe(self._audio_queue.put(None), self.main_loop)

    async def start_realtime_transcription_from_mic(self):
        """
        ãƒã‚¤ã‚¯ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼æ–‡å­—èµ·ã“ã—çµæœã‚’éåŒæœŸã§è¿”ã™ã€‚
        """
        if self._is_running:
            logger.warning("æ—¢ã«å®Ÿè¡Œä¸­ã ã‚ˆã‚“ï¼")
            return

        logger.info("ğŸš€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–‹å§‹æº–å‚™...")
        self._is_running = True
        self._stop_event.clear()
        while not self._audio_queue.empty():
            self._audio_queue.get_nowait()

        # SentimentWorker ã‚’é–‹å§‹ (ã‚‚ã—ã‚ã‚Œã°)
        if self.sentiment_worker:
            logger.info("ğŸ˜Š SentimentWorkerã‚’é–‹å§‹ã—ã¾ã™...")
            try:
                # SentimentWorkerã®startã¯éåŒæœŸãªã®ã§awaitã™ã‚‹
                success = await self.sentiment_worker.start()
                if success:
                    logger.info("ğŸ˜Š SentimentWorkerãŒæ­£å¸¸ã«é–‹å§‹ã•ã‚Œã¾ã—ãŸã€‚")
                else:
                    logger.error("ğŸ˜± SentimentWorkerã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä»¥é™ã®æ„Ÿæƒ…åˆ†æã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã€‚")
                    # self.sentiment_worker = None # é–‹å§‹å¤±æ•—ã—ãŸã‚‰ç„¡åŠ¹åŒ–ã‚‚æ¤œè¨
            except Exception as e:
                logger.exception("ğŸ˜± SentimentWorkerã®startå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                # self.sentiment_worker = None

        loop = asyncio.get_event_loop()
        self._microphone_task = loop.run_in_executor(None, self._microphone_worker)
        logger.info("ğŸ§ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹ï¼")

        try:
            responses = await self.speech_client.streaming_recognize(
                requests=self._microphone_stream_generator()
            )
            async for response in responses:
                if not self._is_running: break

                if not response.results:
                    continue
                result = response.results[0]
                if not result.alternatives:
                    continue
                transcript = result.alternatives[0].transcript
                
                if result.is_final:
                    logger.info(f"âœ¨ æœ€çµ‚çµæœã‚­ã‚¿ã‚³ãƒ¬ï¼: {transcript}")
                    # æœ€çµ‚çµæœãƒ†ã‚­ã‚¹ãƒˆã‚’SentimentWorkerã«é€ä¿¡
                    if self.sentiment_worker and self.sentiment_worker._is_running and transcript:
                        logger.debug(f"æ„Ÿæƒ…åˆ†æã®ãŸã‚ã«ãƒ†ã‚­ã‚¹ãƒˆé€ä¿¡: '{transcript}'")
                        # send_text_for_analysis ã¯éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ãªã®ã§ create_task ã§ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã«å®Ÿè¡Œ
                        asyncio.create_task(self.sentiment_worker.send_text_for_analysis(transcript))
                    
                    # --- Geminiè©•ä¾¡ã‚’ãƒˆãƒªã‚¬ãƒ¼ ---
                    if self.gemini_enabled and transcript:
                        logger.info(f"ğŸ‘‘ Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã«æœ€çµ‚å›ç­”ã‚’é€ä¿¡ã—ã¾ã™: '{transcript[:50]}...'")
                        # ãƒ”ãƒƒãƒã¨æ„Ÿæƒ…ã®ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ (ç¾åœ¨ã¯ãƒ€ãƒŸãƒ¼/éƒ¨åˆ†çš„)
                        # TODO: PitchWorkerã¨SentimentWorkerã‹ã‚‰ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãä½¿ã†
                        current_pitch_summary = {
                            "average_pitch": sum(self.last_pitch_analysis_summary.get("pitches", [0])) / len(self.last_pitch_analysis_summary.get("pitches", [1])) if self.last_pitch_analysis_summary.get("pitches") else "N/A",
                            "pitch_range": max(self.last_pitch_analysis_summary.get("pitches", [0])) - min(self.last_pitch_analysis_summary.get("pitches", [0])) if self.last_pitch_analysis_summary.get("pitches") else "N/A",
                            "speaking_rate": "N/A (TODO)", # TODO: è©±é€Ÿè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
                            "pause_frequency": "N/A (TODO)", # TODO: ãƒãƒ¼ã‚ºé »åº¦è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
                            "average_pause_duration": "N/A (TODO)" # TODO: å¹³å‡ãƒãƒ¼ã‚ºæ™‚é–“è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
                        }
                        
                        asyncio.create_task(self._trigger_gemini_evaluation(
                            self.current_interview_question,
                            transcript,
                            current_pitch_summary, # ä»Šã¯ãƒ€ãƒŸãƒ¼ã«è¿‘ã„
                            self.last_emotion_analysis_summary # SentimentWorkerã‹ã‚‰ã®çµæœ
                        ))
                    # --- ã“ã“ã¾ã§Geminiè©•ä¾¡ãƒˆãƒªã‚¬ãƒ¼ ---
                    yield transcript 
                else:
                    logger.info(f"ğŸ“ é€”ä¸­çµæœ: {transcript}")

        except Exception as e:
            logger.exception("ğŸ˜± start_realtime_transcription_from_mic å†…ã® streaming_recognize ãƒ«ãƒ¼ãƒ—ã§ã‚¨ãƒ©ãƒ¼")
        finally:
            logger.info("ğŸ›‘ æ–‡å­—èµ·ã“ã—å‡¦ç†ãƒ«ãƒ¼ãƒ—çµ‚äº†ã€‚stop_realtime_transcription_from_mic ã‚’å‘¼ã³å‡ºã™æº–å‚™...")
            # await self.stop_realtime_transcription_from_mic() # å‘¼ã³å‡ºã—å…ƒã§ã‚„ã‚‹ï¼

    async def stop_realtime_transcription_from_mic(self):
        """
        ãƒã‚¤ã‚¯å…¥åŠ›ã¨æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’åœæ­¢ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if not self._is_running:
            logger.info("ã‚‚ã†æ­¢ã¾ã£ã¦ã‚‹ã‚ˆã‚“ï¼")
            return

        logger.info("â³ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—åœæ­¢å‡¦ç†é–‹å§‹...")
        self._is_running = False
        self._stop_event.set()

        # SentimentWorker ã‚’åœæ­¢ (ã‚‚ã—ã‚ã‚Œã°)
        if self.sentiment_worker and self.sentiment_worker._is_running:
            logger.info("ğŸ˜Š SentimentWorkerã‚’åœæ­¢ã—ã¾ã™...")
            try:
                # SentimentWorkerã®stopã¯éåŒæœŸãªã®ã§awaitã™ã‚‹
                await self.sentiment_worker.stop()
                logger.info("ğŸ˜Š SentimentWorkerãŒæ­£å¸¸ã«åœæ­¢ã•ã‚Œã¾ã—ãŸã€‚")
            except Exception as e:
                logger.exception("ğŸ˜± SentimentWorkerã®stopå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

        if self._microphone_task is not None:
            logger.info("ğŸ¤ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†å¾…ã¡...")
            try:
                await asyncio.wait_for(self._audio_queue.put(None), timeout=1.0)
            except asyncio.TimeoutError:
                logger.warning("audio_queue.put(None) ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (stopæ™‚)")
            except Exception as e:
                 logger.error(f"audio_queue.put(None) ã§ã‚¨ãƒ©ãƒ¼ (stopæ™‚): {e}")

            try:
                await asyncio.wait_for(self._microphone_task, timeout=5.0)
                logger.info("ğŸ¤ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰æ­£å¸¸çµ‚äº†ï¼")
            except asyncio.TimeoutError:
                logger.warning("ğŸ”¥ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼")
            except Exception as e:
                logger.error(f"ğŸ”¥ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†æ™‚ã«ã‚¨ãƒ©ãƒ¼: {e}")
            self._microphone_task = None
        
        while not self._audio_queue.empty():
            try:
                self._audio_queue.get_nowait()
            except asyncio.QueueEmpty:
                break
        
        logger.info("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—åœæ­¢å®Œäº†ï¼")

    def __del__(self):
        """
        ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæ¶ˆãˆã‚‹ã¨ãã«PyAudioãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã™ã‚‹ã‚ˆã‚“
        """
        if hasattr(self, 'pyaudio_instance') and self.pyaudio_instance:
            logger.info("ğŸ’¨ PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£æ”¾ã—ã¾ã™...")
            self.pyaudio_instance.terminate()
            logger.info("ğŸ’¨ PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è§£æ”¾å®Œäº†ï¼")
        # SentimentWorkerã®aiohttpã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚‚ã“ã“ã§ç¢ºå®Ÿã«é–‰ã˜ã‚‹ã“ã¨ã‚’æ¤œè¨
        # ãŸã ã—ã€éåŒæœŸã®stopãƒ¡ã‚½ãƒƒãƒ‰ã§å‡¦ç†ã™ã‚‹ã®ãŒæœ›ã¾ã—ã„
        # if hasattr(self, 'sentiment_worker') and self.sentiment_worker:
        #     if hasattr(self.sentiment_worker, '_aiohttp_session') and self.sentiment_worker._aiohttp_session:
        #         if not self.sentiment_worker._aiohttp_session.closed:
        #             # éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ __del__ ã‹ã‚‰å‘¼ã¶ã®ã¯é›£ã—ã„ã®ã§ã€é€šå¸¸ã¯ stop ã§å‡¦ç†ã™ã¹ã
        #             logger.warning("SentimentWorkerã®aiohttpã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒ __del__ ã§ã¾ã é–‹ã„ã¦ã„ã¾ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†å‰ã«stopã‚’å‘¼ã‚“ã§ãã ã•ã„ã€‚")

    # --- Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ  ---
    def set_interview_question(self, question: str):
        """ç¾åœ¨ã®é¢æ¥ã®è³ªå•ã‚’è¨­å®šã™ã‚‹ã‚ˆã‚“ï¼"""
        self.current_interview_question = question
        logger.info(f"ğŸ¤ è¨­å®šã•ã‚ŒãŸé¢æ¥ã®è³ªå•: {question}")

    async def _trigger_gemini_evaluation(
        self,
        interview_question: str,
        transcript: str,
        pitch_analysis: dict,
        emotion_analysis: dict
    ):
        """Geminiè©•ä¾¡APIã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã™ã‚‹å†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰"""
        logger.info("ğŸ‘‘ Geminiè©•ä¾¡å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        evaluation_result_text = await get_gemini_evaluation(
            interview_question,
            transcript,
            pitch_analysis,
            emotion_analysis
        )
        if evaluation_result_text:
            parsed_evaluation = parse_gemini_response_data(evaluation_result_text)
            logger.info("--- âœ¨ğŸ‘‘ Gemini AIé¢æ¥è©•ä¾¡çµæœ ğŸ‘‘âœ¨ ---")
            # JSONå½¢å¼ã§ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã¨è¦‹ã‚„ã™ã„ã‹ã‚‚ï¼
            try:
                # è©•ä¾¡çµæœãŒã‚‚ã—JSONæ–‡å­—åˆ—ãªã‚‰ã€æ•´å½¢ã—ã¦è¡¨ç¤ºè©¦ã¿ã‚‹
                # ä»Šå›ã¯parse_gemini_response_dataãŒdictã‚’è¿”ã™ã®ã§ãã®ã¾ã¾è¡¨ç¤º
                logger.info(json.dumps(parsed_evaluation, indent=2, ensure_ascii=False))
            except json.JSONDecodeError:
                logger.info(parsed_evaluation.get("raw_evaluation", "è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãªã—")) # ç”Ÿã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            logger.info("--- ğŸ‘‘ Geminiè©•ä¾¡çµ‚äº† ğŸ‘‘ ---")
            # TODO: å¿…è¦ã§ã‚ã‚Œã°ã€ã“ã®è©•ä¾¡çµæœã‚’ã©ã“ã‹ã«ä¿å­˜ã—ãŸã‚Šã€UIã«é€šçŸ¥ã—ãŸã‚Šã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
        else:
            logger.error("ğŸ˜¢ Geminiã‹ã‚‰ã®è©•ä¾¡å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    # --- ã“ã“ã¾ã§Geminiè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ ---


async def main():
    # logger.setLevel(logging.DEBUG) # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚‚è¦‹ãŸã„å ´åˆã¯ã€ã“ã“ã§ä¸€æ™‚çš„ã«ãƒ¬ãƒ™ãƒ«å¤‰æ›´ï¼
    logger.info("ğŸš€ ãƒ¡ã‚¤ãƒ³å‡¦ç†é–‹å§‹ï¼ SpeechProcessorã®ãƒ†ã‚¹ãƒˆã ã‚ˆã‚“ï¼")
    
    # ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        logger.warning("âš ï¸ ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        logger.warning("   Google Cloud Natural Language API ã®èªè¨¼ã«å¤±æ•—ã—ã€æ„Ÿæƒ…åˆ†æãŒæ©Ÿèƒ½ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        logger.warning("   è¨­å®šä¾‹: export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/keyfile.json\"")
        # SentimentWorkerã®åˆæœŸåŒ–ã¯ language_client ãŒ None ã«ãªã‚‹ã ã‘ã§ã€ã‚¨ãƒ©ãƒ¼ã«ã¯ãªã‚‰ãªã„ã¯ãšã ã‹ã‚‰å‡¦ç†ã¯ç¶šè¡Œ

    processor = SpeechProcessor()

    try:
        logger.info("ãƒã‚¤ã‚¯ã‹ã‚‰ã®æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ (ç´„20ç§’é–“)...")
        processor.set_interview_question("ã‚ãªãŸã®æœ€å¤§ã®å¼·ã¿ã¨ã€ãã‚Œã‚’ã©ã®ã‚ˆã†ã«ä»•äº‹ã«æ´»ã‹ã›ã‚‹ã‹æ•™ãˆã¦ãã ã•ã„ã€‚") # ãƒ†ã‚¹ãƒˆç”¨ã®è³ªå•ã‚’è¨­å®š

        async def transcribe_task_wrapper():
            # transcribe_taskå†…ã‹ã‚‰processorã®çŠ¶æ…‹ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
            nonlocal processor 
            async for transcript in processor.start_realtime_transcription_from_mic():
                # logger.info(f"ğŸ“¢ ãƒ¡ã‚¤ãƒ³å—ä¿¡ (æœ€çµ‚çµæœ): {transcript}") # ã“ã‚Œã¯ SpeechProcessor å´ã§ãƒ­ã‚°å‡ºåŠ›
                if not processor._is_running: 
                    break
        
        transcription_coro = transcribe_task_wrapper()
        main_task = asyncio.create_task(transcription_coro)
        
        await asyncio.sleep(20) # 20ç§’é–“å®Ÿè¡Œ
        logger.info("\nâ³ 20ç§’çµŒéã€æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢ã—ã¾ã™...\n")
        
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ Ctrl+C ã‚’æ¤œçŸ¥ï¼å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™...")
    except Exception as e:
        logger.exception(f"ğŸ˜± ãƒ¡ã‚¤ãƒ³å‡¦ç†ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        logger.info("ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†é–‹å§‹...")
        if hasattr(processor, '_is_running') and processor._is_running:
             await processor.stop_realtime_transcription_from_mic()
        
        # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è§£æ”¾ã¯ __del__ ã«ä»»ã›ã‚‹ã‹ã€æ˜ç¤ºçš„ã«å‘¼ã¶
        if hasattr(processor, 'pyaudio_instance') and processor.pyaudio_instance:
             processor.pyaudio_instance.terminate() 
        logger.info("ğŸ‘‹ ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Œäº†ï¼ã¾ãŸã­ï½ï¼")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logger.exception(f"ğŸ˜± asyncio.runã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼: {e}")
        logger.error("ğŸ’¡ ã‚‚ã—ã‹ã—ã¦: Google Cloud ã®èªè¨¼è¨­å®šã—ã¦ãªã„ã¨ã‹ï¼Ÿ")
        logger.error("   gcloud auth application-default login ã¨ã‹è©¦ã—ã¦ã¿ã¦ã­ï¼") 