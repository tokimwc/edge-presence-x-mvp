# ã“ã“ã« Google Cloud Speech-to-Text ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹æ„Ÿã˜ã§ï¼
from google.cloud import speech_v1p1beta1 as speech # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ã†ã‚ˆï¼
import asyncio
import pyaudio
import logging # logging ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os # ç’°å¢ƒå¤‰æ•°ã®ãŸã‚ã«è¿½åŠ 

# --- Pythonã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œç´¢ãƒ‘ã‚¹ã«srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ  ---
import sys
# speech_processor.py ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (src/backend/services)
_CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ (src/backend/services -> src/backend -> src)
_SRC_DIR = os.path.abspath(os.path.join(_CURRENT_FILE_DIR, '..', '..'))
if _SRC_DIR not in sys.path:
    sys.path.insert(0, _SRC_DIR)
# --- ã“ã“ã¾ã§ ---

# Worker ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (ç›¸å¯¾ãƒ‘ã‚¹ã‹ã‚‰srcã‚’åŸºæº–ã¨ã—ãŸçµ¶å¯¾ãƒ‘ã‚¹é¢¨ã«å¤‰æ›´)
from backend.workers.pitch_worker import PitchWorker
from backend.workers.sentiment_worker import SentimentWorker # SentimentWorker ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# logging ã®åŸºæœ¬è¨­å®š (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ï¼‘å›ã ã‘å®Ÿè¡Œ)
# SpeechProcessor ã‚¯ãƒ©ã‚¹ã®å¤–ã§è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ã‚ˆã‚“ï¼
logging.basicConfig(
    level=logging.INFO,  # é–‹ç™ºä¸­ã¯INFOãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã‚’è¡¨ç¤º
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
# ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = logging.getLogger(__name__)

# PyAudioã®è¨­å®š (ã“ã‚Œã‚‰ã®å€¤ã¯ãƒã‚¤ã‚¯ã‚„è¦ä»¶ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ã­ï¼)
FORMAT = pyaudio.paInt16  # éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (16bit)
CHANNELS = 1             # ãƒ¢ãƒãƒ©ãƒ«
RATE = 16000             # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ (16kHz)
CHUNK = int(RATE / 10)   # 100msåˆ†ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º (Speech-to-Textã®æ¨å¥¨ã«åˆã‚ã›ã¦)
SAMPLE_WIDTH = pyaudio.PyAudio().get_sample_size(FORMAT) # PyAudioã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«å¹…ã‚’å–å¾—

class SpeechProcessor:
    def __init__(self):
        self.speech_client = speech.SpeechAsyncClient()
        self.pyaudio_instance = pyaudio.PyAudio()
        self._audio_queue = asyncio.Queue()
        self._is_running = False
        self._microphone_task = None
        self._stop_event = asyncio.Event()
        self.main_loop = asyncio.get_event_loop()

        # PitchWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            self.pitch_worker = PitchWorker(
                sample_rate=RATE,
                channels=CHANNELS,
                sample_width=SAMPLE_WIDTH,
            )
            logger.info("ğŸµ PitchWorker ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± PitchWorker ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.pitch_worker = None

        # SentimentWorker ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            # Google Cloud Natural Language API ã‚’ä½¿ã†ã®ã§ã€APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ã§è¨­å®šã•ã‚Œã¦ã‚‹å‰æã ã‚ˆã‚“ï¼
            self.sentiment_worker = SentimentWorker(
                on_emotion_callback=self._handle_emotion_data,
                language_code="ja" # Google Cloud NL API ã¯ "ja" ã‚’ä½¿ã†ã‚ˆï¼
            )
            logger.info("ğŸ˜Š SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e: # SentimentWorkerå†…ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã‚‚ã‚­ãƒ£ãƒƒãƒã§ãã‚‹ã‚ˆã†ã«æ±ç”¨çš„ãªExceptionã«
            logger.exception("ğŸ˜± SentimentWorker (Google Cloud NL APIç‰ˆ) ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            self.sentiment_worker = None

        logger.info("âœ¨ SpeechProcessor åˆæœŸåŒ–å®Œäº†ï¼âœ¨")
        logger.info(f"PyAudioè¨­å®š: FORMAT={FORMAT}, CHANNELS={CHANNELS}, RATE={RATE}, CHUNK={CHUNK}, SAMPLE_WIDTH={SAMPLE_WIDTH}")

    def _handle_emotion_data(self, emotion_data: dict):
        """
        SentimentWorkerã‹ã‚‰ã®æ„Ÿæƒ…åˆ†æçµæœã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã€‚
        Google Cloud Natural Language API ã®çµæœã«åˆã‚ã›ã¦èª¿æ•´ã—ãŸã‚ˆã‚“ï¼
        """
        # Natural Language API ã‹ã‚‰ã¯ score ã¨ magnitude ãŒãƒ¡ã‚¤ãƒ³ã§è¿”ã£ã¦ãã‚‹
        score = emotion_data.get("emotions", {}).get("score")
        magnitude = emotion_data.get("emotions", {}).get("magnitude")
        text_processed = emotion_data.get("text_processed", "")

        if score is not None and magnitude is not None:
            logger.info(f"ğŸ˜Š æ„Ÿæƒ…åˆ†æçµæœ (Google NL): ã‚¹ã‚³ã‚¢={score:.2f}, å¼·ã•={magnitude:.2f} (ãƒ†ã‚­ã‚¹ãƒˆ: '{text_processed[:50]}...')")
        else:
            logger.warning(f"ğŸ¤” æ„Ÿæƒ…åˆ†æçµæœãŒä¸å®Œå…¨ã§ã™: {emotion_data}")

    async def _microphone_stream_generator(self):
        """
        ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’éåŒæœŸã§ä¾›çµ¦ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã ã‚ˆã‚“ï¼
        Speech-to-Text API ãŒæœŸå¾…ã™ã‚‹ StreamingRecognitionConfig ã¨éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ yield ã™ã‚‹ã€‚
        """
        streaming_config = speech.StreamingRecognitionConfig(
            config=speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=RATE,
                language_code="ja-JP",
                enable_automatic_punctuation=True,
            ),
            interim_results=True,
        )
        yield speech.StreamingRecognizeRequest(streaming_config=streaming_config)
        logger.info("ğŸ¤ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šé€ä¿¡å®Œäº†ï¼éŸ³å£°å¾…æ©Ÿä¸­...")

        while self._is_running and not self._stop_event.is_set():
            try:
                chunk = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                if chunk is None: 
                    break
                yield speech.StreamingRecognizeRequest(audio_content=chunk)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.exception("ğŸ˜± _microphone_stream_generator ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼")
                break
        logger.info("ğŸ¤ _microphone_stream_generator çµ‚äº†")

    def _microphone_worker(self):
        """
        PyAudioã‚’ä½¿ã£ã¦ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹åŒæœŸå‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ã€‚
        ã“ã‚Œã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹æƒ³å®šã ã‚ˆã‚“ï¼
        """
        try:
            stream = self.pyaudio_instance.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
            )
            logger.info("ğŸ™ï¸ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹ï¼ éŸ³å£°åé›†ä¸­...")
            data_counter = 0 # ãƒ‡ãƒãƒƒã‚°ç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            while self._is_running and not self._stop_event.is_set():
                try:
                    data = stream.read(CHUNK, exception_on_overflow=False)
                    data_counter += 1
                    
                    log_pitch_str = "N/A"
                    if self.pitch_worker and data:
                        try:
                            pitch_hz = self.pitch_worker.analyze_pitch(data)
                            if pitch_hz is not None:
                                log_pitch_str = f"{pitch_hz:.2f} Hz"
                        except Exception as e:
                            logger.error(f"ğŸ˜± (Worker) PitchWorkerã§ã®ãƒ”ãƒƒãƒè§£æã‚¨ãƒ©ãƒ¼: {e}")
                            log_pitch_str = "Error"

                    logger.debug(f"ğŸ¤ [Worker-{data_counter}] ãƒãƒ£ãƒ³ã‚¯å—ä¿¡ï¼ ã‚µã‚¤ã‚º: {len(data)}, å…ˆé ­10ãƒã‚¤ãƒˆ: {data[:10].hex() if data else 'None'} | ğŸµ ãƒ”ãƒƒãƒ: {log_pitch_str}")
                    
                    asyncio.run_coroutine_threadsafe(self._audio_queue.put(data), self.main_loop)
                except IOError as e:
                    logger.warning(f"ğŸ¤ PyAudio readã‚¨ãƒ©ãƒ¼ (ãŸã¶ã‚“ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼): {e}") 
                    asyncio.run_coroutine_threadsafe(asyncio.sleep(0.01), self.main_loop)
                except Exception as e:
                    logger.exception(f"ğŸ˜± _microphone_workerã®å†…éƒ¨ãƒ«ãƒ¼ãƒ—ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ«ãƒ¼ãƒ—ã‚’ç¶™ç¶šã™ã‚‹ãŸã‚ã« à´šàµ†à´±à´¿à´¯å¾…æ©Ÿæ™‚é–“ã‚’è¨­ã‘ã‚‹ã“ã¨ã‚‚æ¤œè¨
                    asyncio.run_coroutine_threadsafe(asyncio.sleep(0.01), self.main_loop)

            logger.info("ğŸ™ï¸ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ«ãƒ¼ãƒ—çµ‚äº†ã€‚ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢å‡¦ç†ã¸...")
            stream.stop_stream()
            stream.close()
            logger.info("ğŸ™ï¸ ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ æ­£å¸¸çµ‚äº†ã€‚")
        except Exception as e:
            logger.exception("ğŸ˜± _microphone_workerã§è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼")
        finally:
            if self._is_running: 
                 logger.info("_microphone_worker ã® finally ã§ã‚­ãƒ¥ãƒ¼ã«Noneã‚’é€ä¿¡")
                 asyncio.run_coroutine_threadsafe(self._audio_queue.put(None), self.main_loop)

    async def start_realtime_transcription_from_mic(self):
        """
        ãƒã‚¤ã‚¯ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã™ã‚‹ã‚ˆã‚“ï¼æ–‡å­—èµ·ã“ã—çµæœã‚’éåŒæœŸã§è¿”ã™ã€‚
        """
        if self._is_running:
            logger.warning("æ—¢ã«å®Ÿè¡Œä¸­ã ã‚ˆã‚“ï¼")
            return

        logger.info("ğŸš€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–‹å§‹æº–å‚™...")
        self._is_running = True
        self._stop_event.clear()
        while not self._audio_queue.empty():
            self._audio_queue.get_nowait()

        # SentimentWorker ã‚’é–‹å§‹ (ã‚‚ã—ã‚ã‚Œã°)
        if self.sentiment_worker:
            logger.info("ğŸ˜Š SentimentWorkerã‚’é–‹å§‹ã—ã¾ã™...")
            try:
                # SentimentWorkerã®startã¯éåŒæœŸãªã®ã§awaitã™ã‚‹
                success = await self.sentiment_worker.start()
                if success:
                    logger.info("ğŸ˜Š SentimentWorkerãŒæ­£å¸¸ã«é–‹å§‹ã•ã‚Œã¾ã—ãŸã€‚")
                else:
                    logger.error("ğŸ˜± SentimentWorkerã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä»¥é™ã®æ„Ÿæƒ…åˆ†æã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã€‚")
                    # self.sentiment_worker = None # é–‹å§‹å¤±æ•—ã—ãŸã‚‰ç„¡åŠ¹åŒ–ã‚‚æ¤œè¨
            except Exception as e:
                logger.exception("ğŸ˜± SentimentWorkerã®startå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                # self.sentiment_worker = None

        loop = asyncio.get_event_loop()
        self._microphone_task = loop.run_in_executor(None, self._microphone_worker)
        logger.info("ğŸ§ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹ï¼")

        try:
            responses = await self.speech_client.streaming_recognize(
                requests=self._microphone_stream_generator()
            )
            async for response in responses:
                if not self._is_running: break

                if not response.results:
                    continue
                result = response.results[0]
                if not result.alternatives:
                    continue
                transcript = result.alternatives[0].transcript
                
                if result.is_final:
                    logger.info(f"âœ¨ æœ€çµ‚çµæœã‚­ã‚¿ã‚³ãƒ¬ï¼: {transcript}")
                    # æœ€çµ‚çµæœãƒ†ã‚­ã‚¹ãƒˆã‚’SentimentWorkerã«é€ä¿¡
                    if self.sentiment_worker and self.sentiment_worker._is_running and transcript:
                        logger.debug(f"æ„Ÿæƒ…åˆ†æã®ãŸã‚ã«ãƒ†ã‚­ã‚¹ãƒˆé€ä¿¡: '{transcript}'")
                        # send_text_for_analysis ã¯éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ãªã®ã§ create_task ã§ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã«å®Ÿè¡Œ
                        asyncio.create_task(self.sentiment_worker.send_text_for_analysis(transcript))
                    yield transcript 
                else:
                    logger.info(f"ğŸ“ é€”ä¸­çµæœ: {transcript}")

        except Exception as e:
            logger.exception("ğŸ˜± start_realtime_transcription_from_mic å†…ã® streaming_recognize ãƒ«ãƒ¼ãƒ—ã§ã‚¨ãƒ©ãƒ¼")
        finally:
            logger.info("ğŸ›‘ æ–‡å­—èµ·ã“ã—å‡¦ç†ãƒ«ãƒ¼ãƒ—çµ‚äº†ã€‚stop_realtime_transcription_from_mic ã‚’å‘¼ã³å‡ºã™æº–å‚™...")
            # await self.stop_realtime_transcription_from_mic() # å‘¼ã³å‡ºã—å…ƒã§ã‚„ã‚‹ï¼

    async def stop_realtime_transcription_from_mic(self):
        """
        ãƒã‚¤ã‚¯å…¥åŠ›ã¨æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’åœæ­¢ã™ã‚‹ã‚ˆã‚“ï¼
        """
        if not self._is_running:
            logger.info("ã‚‚ã†æ­¢ã¾ã£ã¦ã‚‹ã‚ˆã‚“ï¼")
            return

        logger.info("â³ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—åœæ­¢å‡¦ç†é–‹å§‹...")
        self._is_running = False
        self._stop_event.set()

        # SentimentWorker ã‚’åœæ­¢ (ã‚‚ã—ã‚ã‚Œã°)
        if self.sentiment_worker and self.sentiment_worker._is_running:
            logger.info("ğŸ˜Š SentimentWorkerã‚’åœæ­¢ã—ã¾ã™...")
            try:
                # SentimentWorkerã®stopã¯éåŒæœŸãªã®ã§awaitã™ã‚‹
                await self.sentiment_worker.stop()
                logger.info("ğŸ˜Š SentimentWorkerãŒæ­£å¸¸ã«åœæ­¢ã•ã‚Œã¾ã—ãŸã€‚")
            except Exception as e:
                logger.exception("ğŸ˜± SentimentWorkerã®stopå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

        if self._microphone_task is not None:
            logger.info("ğŸ¤ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†å¾…ã¡...")
            try:
                await asyncio.wait_for(self._audio_queue.put(None), timeout=1.0)
            except asyncio.TimeoutError:
                logger.warning("audio_queue.put(None) ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (stopæ™‚)")
            except Exception as e:
                 logger.error(f"audio_queue.put(None) ã§ã‚¨ãƒ©ãƒ¼ (stopæ™‚): {e}")

            try:
                await asyncio.wait_for(self._microphone_task, timeout=5.0)
                logger.info("ğŸ¤ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰æ­£å¸¸çµ‚äº†ï¼")
            except asyncio.TimeoutError:
                logger.warning("ğŸ”¥ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼")
            except Exception as e:
                logger.error(f"ğŸ”¥ ãƒã‚¤ã‚¯ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†æ™‚ã«ã‚¨ãƒ©ãƒ¼: {e}")
            self._microphone_task = None
        
        while not self._audio_queue.empty():
            try:
                self._audio_queue.get_nowait()
            except asyncio.QueueEmpty:
                break
        
        logger.info("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—åœæ­¢å®Œäº†ï¼")

    def __del__(self):
        """
        ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæ¶ˆãˆã‚‹ã¨ãã«PyAudioãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã™ã‚‹ã‚ˆã‚“
        """
        if hasattr(self, 'pyaudio_instance') and self.pyaudio_instance:
            logger.info("ğŸ’¨ PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£æ”¾ã—ã¾ã™...")
            self.pyaudio_instance.terminate()
            logger.info("ğŸ’¨ PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è§£æ”¾å®Œäº†ï¼")
        # SentimentWorkerã®aiohttpã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚‚ã“ã“ã§ç¢ºå®Ÿã«é–‰ã˜ã‚‹ã“ã¨ã‚’æ¤œè¨
        # ãŸã ã—ã€éåŒæœŸã®stopãƒ¡ã‚½ãƒƒãƒ‰ã§å‡¦ç†ã™ã‚‹ã®ãŒæœ›ã¾ã—ã„
        # if hasattr(self, 'sentiment_worker') and self.sentiment_worker:
        #     if hasattr(self.sentiment_worker, '_aiohttp_session') and self.sentiment_worker._aiohttp_session:
        #         if not self.sentiment_worker._aiohttp_session.closed:
        #             # éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ __del__ ã‹ã‚‰å‘¼ã¶ã®ã¯é›£ã—ã„ã®ã§ã€é€šå¸¸ã¯ stop ã§å‡¦ç†ã™ã¹ã
        #             logger.warning("SentimentWorkerã®aiohttpã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒ __del__ ã§ã¾ã é–‹ã„ã¦ã„ã¾ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†å‰ã«stopã‚’å‘¼ã‚“ã§ãã ã•ã„ã€‚")


async def main():
    # logger.setLevel(logging.DEBUG) # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚‚è¦‹ãŸã„å ´åˆã¯ã€ã“ã“ã§ä¸€æ™‚çš„ã«ãƒ¬ãƒ™ãƒ«å¤‰æ›´ï¼
    logger.info("ğŸš€ ãƒ¡ã‚¤ãƒ³å‡¦ç†é–‹å§‹ï¼ SpeechProcessorã®ãƒ†ã‚¹ãƒˆã ã‚ˆã‚“ï¼")
    
    # ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        logger.warning("âš ï¸ ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        logger.warning("   Google Cloud Natural Language API ã®èªè¨¼ã«å¤±æ•—ã—ã€æ„Ÿæƒ…åˆ†æãŒæ©Ÿèƒ½ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        logger.warning("   è¨­å®šä¾‹: export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/keyfile.json\"")
        # SentimentWorkerã®åˆæœŸåŒ–ã¯ language_client ãŒ None ã«ãªã‚‹ã ã‘ã§ã€ã‚¨ãƒ©ãƒ¼ã«ã¯ãªã‚‰ãªã„ã¯ãšã ã‹ã‚‰å‡¦ç†ã¯ç¶šè¡Œ

    processor = SpeechProcessor()

    try:
        logger.info("ãƒã‚¤ã‚¯ã‹ã‚‰ã®æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ (ç´„20ç§’é–“)...")
        
        async def transcribe_task_wrapper():
            # transcribe_taskå†…ã‹ã‚‰processorã®çŠ¶æ…‹ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
            nonlocal processor 
            async for transcript in processor.start_realtime_transcription_from_mic():
                # logger.info(f"ğŸ“¢ ãƒ¡ã‚¤ãƒ³å—ä¿¡ (æœ€çµ‚çµæœ): {transcript}") # ã“ã‚Œã¯ SpeechProcessor å´ã§ãƒ­ã‚°å‡ºåŠ›
                if not processor._is_running: 
                    break
        
        transcription_coro = transcribe_task_wrapper()
        main_task = asyncio.create_task(transcription_coro)
        
        await asyncio.sleep(20) # 20ç§’é–“å®Ÿè¡Œ
        logger.info("\nâ³ 20ç§’çµŒéã€æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢ã—ã¾ã™...\n")
        
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ Ctrl+C ã‚’æ¤œçŸ¥ï¼å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™...")
    except Exception as e:
        logger.exception(f"ğŸ˜± ãƒ¡ã‚¤ãƒ³å‡¦ç†ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        logger.info("ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†é–‹å§‹...")
        if hasattr(processor, '_is_running') and processor._is_running:
             await processor.stop_realtime_transcription_from_mic()
        
        # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è§£æ”¾ã¯ __del__ ã«ä»»ã›ã‚‹ã‹ã€æ˜ç¤ºçš„ã«å‘¼ã¶
        if hasattr(processor, 'pyaudio_instance') and processor.pyaudio_instance:
             processor.pyaudio_instance.terminate() 
        logger.info("ğŸ‘‹ ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Œäº†ï¼ã¾ãŸã­ï½ï¼")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logger.exception(f"ğŸ˜± asyncio.runã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼: {e}")
        logger.error("ğŸ’¡ ã‚‚ã—ã‹ã—ã¦: Google Cloud ã®èªè¨¼è¨­å®šã—ã¦ãªã„ã¨ã‹ï¼Ÿ")
        logger.error("   gcloud auth application-default login ã¨ã‹è©¦ã—ã¦ã¿ã¦ã­ï¼") 